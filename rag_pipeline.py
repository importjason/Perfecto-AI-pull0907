# rag_pipeline.py

import streamlit as st
import asyncio
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import SeleniumURLLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains.combine_documents import create_stuff_documents_chain
from file_handler import get_documents_from_files
import faiss
from langchain.embeddings import HuggingFaceEmbeddings
import os
import requests
from langchain.llms.base import LLM
from typing import Optional, List
from groq import Groq
from pydantic import PrivateAttr 

class GROQLLM(LLM):
    model: str = "meta-llama/llama-4-scout-17b-16e-instruct"
    
    _api_key: str = PrivateAttr() 
    _client: Groq = PrivateAttr() 

    def __init__(self, api_key: str, model: str = "meta-llama/llama-4-scout-17b-16e-instruct", **kwargs):
        super().__init__(model=model, **kwargs)
        
        self._api_key = api_key 
        self._client = Groq(api_key=self._api_key) 

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        messages = [{"role": "user", "content": prompt}]
        completion = self._client.chat.completions.create( 
            model=self.model,
            messages=messages,
            temperature=0.6,
            max_completion_tokens=512,
            top_p=0.95,
            stream=False,
            stop=stop,
        )
        return completion.choices[0].message.content

    @property
    def _identifying_params(self):
        return {"model": self.model}

    @property
    def _llm_type(self) -> str:
        return "groq"
    
def get_retriever_from_source(source_type, source_input):
    documents = [] 
    with st.status("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...", expanded=True) as status:
        if source_type == "URL":
            status.update(label="URL ì»¨í…ì¸ ë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...")
            loader = SeleniumURLLoader(urls=[source_input])
            documents = loader.load()
        elif source_type == "Files":
            status.update(label="íŒŒì¼ì„ íŒŒì‹±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            documents = get_documents_from_files(source_input)
        elif source_type == "FAISS":
            embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-sts")
            if os.path.isdir(source_input):
                index_dir = source_input
            else:
                st.error(f"ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤: {source_input}")
                return None

            # ìœ„í—˜ ê°ìˆ˜í•˜ê³  ë¡œë“œ í—ˆìš© (ë³¸ì¸ì´ ë§Œë“  ì¸ë±ìŠ¤ë¼ë©´ OK)
            retriever = FAISS.load_local(
                index_dir,
                embeddings,
                allow_dangerous_deserialization=True
            ).as_retriever()
            return retriever

        if not documents:
            status.update(label="ë¬¸ì„œ ë¡œë”© ì‹¤íŒ¨.", state="error")
            return None

        status.update(label="ë¬¸ì„œë¥¼ ì²­í¬(chunk)ë¡œ ë¶„í•  ì¤‘ì…ë‹ˆë‹¤...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=700,
            chunk_overlap=150,
            separators=["\n\n", "\n", " ", ""],
            is_separator_regex=False,
        )
        splits = text_splitter.split_documents(documents)

        status.update(label="ì„ë² ë”© ëª¨ë¸ì„ ë¡œì»¬ì— ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...")
        embeddings = HuggingFaceEmbeddings(model_name='jhgan/ko-sbert-sts')

        status.update(label=f"{len(splits)}ê°œì˜ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        vectorstore = FAISS.from_documents(splits, embeddings)

        retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={'k': 2, 'fetch_k': 10}
        )
        status.update(label="ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!", state="complete")

    return retriever

def get_document_chain(system_prompt):
    rag_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{context}"),
        ]
    )
    groq_api_key = st.secrets["GROQ_API_KEY"]
    llm = GROQLLM(api_key=groq_api_key)
    document_chain = create_stuff_documents_chain(llm, rag_prompt)
    return document_chain

def get_default_chain(system_prompt):
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{question}"),
        ]
    )
    groq_api_key = st.secrets["GROQ_API_KEY"]
    llm = GROQLLM(api_key=groq_api_key)
    return prompt | llm | StrOutputParser()

def get_shorts_script_generation_prompt(user_question_content):
    """
    ìˆí¼ ë¹„ë””ì˜¤ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ LLMì´ íŠ¹ì • í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤.
    """
    return f"""
    ë‹¹ì‹ ì€ TikTok, YouTube Shorts, Instagram Reelsê³¼ ê°™ì€ **ë§¤ë ¥ì ì´ê³  ë°”ì´ëŸ´ì„± ìˆëŠ” ìˆí¼ ë¹„ë””ì˜¤ ìŠ¤í¬ë¦½íŠ¸**ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ í¬ë¦¬ì—ì´í„°ì…ë‹ˆë‹¤.
    ì•„ë˜ 'ì‚¬ìš©ì ìš”ì²­ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ, **ë‹¤ìŒ ì›ì¹™ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ í•œêµ­ì–´ë¡œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.**

    **ğŸŒŸ ìˆí¼ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì›ì¹™ (ë§¤ìš° ì¤‘ìš”!):**
    1.  **ì´ˆê°•ë ¥ í›„í¬ (0-5ì´ˆ):** ì‹œì²­ìì˜ ìŠ¤í¬ë¡¤ì„ ë©ˆì¶”ê²Œ í•  ê°•ë ¥í•œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”!
        ì˜ˆì‹œ: "í˜¹ì‹œ ì•„ì§ë„ ì´ê±¸ ëª¨ë¥¸ë‹¤ê³ ìš”? ğŸ¤¯", "ì´ê±° í•˜ë‚˜ë©´ ëì¥ë‚˜ìš”! ğŸ”¥", "ì¼ë³¸ ìŒì‹? ì™¸êµ­ì¸ì€ ì´ê±° ëª» ë¨¹ì–´ìš”! ğŸ˜±"
    2.  **ê°„ê²°í•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” ë¬¸ì¥:** í•œ ë¬¸ì¥ì— í•˜ë‚˜ì˜ í•µì‹¬ ì•„ì´ë””ì–´ë§Œ ë‹´ê³ , ë¶ˆí•„ìš”í•œ ì„œìˆ ì–´ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.
    3.  **ëŒ€í™”ì²´ / êµ¬ì–´ì²´ ì‚¬ìš©:** ì¹œêµ¬ì—ê²Œ ë§í•˜ë“¯ì´ ì¹œê·¼í•˜ê³  í™œê¸°ì°¬ í†¤ì„ ìœ ì§€í•©ë‹ˆë‹¤.
    4.  **ì‹œê°ì  ìš”ì†Œ ê°•ì¡°:** ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©ì´ ì˜ìƒìœ¼ë¡œ ì–´ë–»ê²Œ í‘œí˜„ë ì§€ ìƒìƒí•  ìˆ˜ ìˆë„ë¡ ìƒë™ê° ìˆê²Œ ë¬˜ì‚¬í•©ë‹ˆë‹¤.
    5.  **ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš© (ì„ íƒ ì‚¬í•­ì´ë‚˜ ê¶Œì¥):** í…ìŠ¤íŠ¸ ì¤‘ê°„ì— ê°ì •ì„ ê°•ì¡°í•˜ëŠ” ì´ëª¨ì§€ë¥¼ í™œìš©í•´ ì‹œê°ì  ì¬ë¯¸ë¥¼ ë”í•©ë‹ˆë‹¤.
    6.  **í…œí¬ ì¡°ì ˆ:** ë¬¸ì¥ê³¼ ë¬¸ì¥ ì‚¬ì´ì— ìì—°ìŠ¤ëŸ¬ìš´ **ê°„ê²°í•œ íœ´ì§€(pause)ê°€ í•„ìš”í•  ê²½ìš° ë°˜ë“œì‹œ 'â€¦' (ë§ì¤„ì„í‘œ)**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    7.  **ëª…í™•í•˜ê³  í–‰ë™ì„ ìœ ë„í•˜ëŠ” Call to Action (CTA):** ë§ˆì§€ë§‰ì—ëŠ” ì‹œì²­ìì—ê²Œ ì¢‹ì•„ìš”, ëŒ“ê¸€, ê³µìœ , íŒ”ë¡œìš°, ë˜ëŠ” íŠ¹ì • í–‰ë™ì„ ìœ ë„í•˜ëŠ” ë¬¸ì¥ì„ ë„£ìŠµë‹ˆë‹¤.
        ì˜ˆì‹œ: "ì¢‹ì•„ìš” ëˆ„ë¥´ê³ , ë‹¤ìŒ ê¿€íŒë„ ë°›ì•„ê°€ì„¸ìš”! ğŸ‘", "ì§€ê¸ˆ ë°”ë¡œ ì‹œë„í•´ë³´ì„¸ìš”! #ê¿€íŒ", "ì¹œêµ¬ì—ê²Œ ì´ ì˜ìƒì„ ê³µìœ í•˜ì„¸ìš”! ğŸš€"
    8.  **ê²°ê³¼ë¬¼ì€ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© ìì²´ë§Œ í¬í•¨:** ì–´ë– í•œ ë¨¸ë¦¬ë§("ë‹¤ìŒì€ ì‡¼ì¸  ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤:"), ê¼¬ë¦¬ë§, ì„¤ëª…ë„ ì—†ì´ ì˜¤ì§ ìŠ¤í¬ë¦½íŠ¸ ë³¸ë¬¸ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.

    ---
    **ì‚¬ìš©ì ìš”ì²­ ë‚´ìš©:**
    {user_question_content}
    ---

    **ìƒì„±í•  ìˆí¼ ìŠ¤í¬ë¦½íŠ¸:**
    """