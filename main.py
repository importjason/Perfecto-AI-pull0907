import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage
from rag_pipeline import get_retriever_from_source, get_document_chain, get_default_chain
from web_ingest import full_web_ingest
from image_generator import generate_images_for_topic
from elevenlabs_tts import generate_tts, TTS_TEMPLATES
from whisper_asr import transcribe_audio_with_timestamps, generate_ass_subtitle, SUBTITLE_TEMPLATES
from video_maker import create_video_with_segments, add_subtitles_to_video
from deep_translator import GoogleTranslator
import os
import requests # ê¸°ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ ì¶”ê°€
import re

# API í‚¤ ë¡œë“œ
load_dotenv()

# --- ì•± ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="Multimodal RAG Chatbot", page_icon="ğŸ¤–")
st.title("ğŸ¤– ë©€í‹°ëª¨ë‹¬ íŒŒì¼/URL ë¶„ì„ RAG ì±—ë´‡")
st.markdown(
    """
ì•ˆë…•í•˜ì„¸ìš”! ì´ ì±—ë´‡ì€ ì›¹ì‚¬ì´íŠ¸ URLì´ë‚˜ ì—…ë¡œë“œëœ íŒŒì¼(PDF, DOCX, TXT)ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤.
"""
)

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "retriever" not in st.session_state:
    st.session_state.retriever = None
if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = "ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì´ì, ìˆí¼(Short-form) ì˜ìƒ ì œì‘ì„ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œì˜ í…ìŠ¤íŠ¸ì™€ í…Œì´ë¸”ì„ ì •í™•íˆ ì´í•´í•˜ê³ , ì§§ê³  ê°„ê²°í•˜ë©° í•µì‹¬ ë‚´ìš©ì„ ë‹´ì€ ì‡¼ì¸  ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì œì‘í•´ì£¼ì„¸ìš”. ìŠ¤í¬ë¦½íŠ¸ ì™¸ì—ëŠ” ì–´ë–¤ ë‹µë³€ë„ í•´ì„œëŠ” ì•ˆë©ë‹ˆë‹¤. ë˜í•œ ë§ˆí¬ë‹¤ìš´ê³¼ ê°™ì€ ê¸°í˜¸ëŠ” ì „ë¶€ ì œê±°í•´ì£¼ì„¸ìš”."
if "last_user_query" not in st.session_state:
    st.session_state.last_user_query = ""
if "video_topic" not in st.session_state:
    st.session_state.video_topic = "" # ì˜ìƒ ì£¼ì œ ì´ˆê¸°í™”
if "edited_script_content" not in st.session_state:
    st.session_state.edited_script_content = "" # ìˆ˜ì • ê°€ëŠ¥í•œ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© ì´ˆê¸°í™”
if "selected_tts_template" not in st.session_state:
    st.session_state.selected_tts_template = "educational"
if "selected_subtitle_template" not in st.session_state:
    st.session_state.selected_subtitle_template = "educational"
if "bgm_path" not in st.session_state:
    st.session_state.bgm_path = None
if "include_voice" not in st.session_state:
    st.session_state.include_voice = True # ìŒì„± í¬í•¨ ì—¬ë¶€ ì´ˆê¸°í™”

# --- ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    st.divider()
    st.subheader("ğŸ¤– AI í˜ë¥´ì†Œë‚˜ ì„¤ì •")
    prompt_input = st.text_area(
        "AIì˜ ì—­í• ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.", value=st.session_state.system_prompt, height=150
    )
    if st.button("í˜ë¥´ì†Œë‚˜ ì ìš©"):
        st.session_state.system_prompt = prompt_input
        st.toast("AI í˜ë¥´ì†Œë‚˜ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.divider()
    st.subheader("ğŸ” ë¶„ì„ ëŒ€ìƒ ì„¤ì •")
    url_input = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥", placeholder="ex) ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬")
    uploaded_files = st.file_uploader(
        "íŒŒì¼ ì—…ë¡œë“œ (PDF, DOCX, TXT)", type=["pdf", "docx", "txt"], accept_multiple_files=True
    )
    st.info("LlamaParseëŠ” í…Œì´ë¸”, í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ë¬¸ì„œ ë¶„ì„ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.", icon="â„¹ï¸")
    
    if st.button("ë¶„ì„ ì‹œì‘"):
        st.session_state.messages = []
        st.session_state.retriever = None
        st.session_state.video_topic = "" # ë¶„ì„ ì‹œì‘ ì‹œ ì˜ìƒ ì£¼ì œ ì´ˆê¸°í™”
        st.session_state.edited_script_content = "" # ë¶„ì„ ì‹œì‘ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© ì´ˆê¸°í™”

        source_type = None
        source_input = None

        if uploaded_files:
            source_type = "Files"
            source_input = uploaded_files

        elif url_input:
            with st.spinner("ì›¹í˜ì´ì§€ë¥¼ ìˆ˜ì§‘í•˜ê³  ë²¡í„°í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                text_path, index_dir, error = full_web_ingest(url_input)
                if not error:
                    source_type = "FAISS"
                    source_input = index_dir  # í´ë” ê²½ë¡œ
                else:
                    st.error(f"ì›¹í˜ì´ì§€ ìˆ˜ì§‘ ë° ë²¡í„°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error}")
        else:
            st.warning("ê²€ìƒ‰ í‚¤ì›Œë“œ ë˜ëŠ” íŒŒì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        if source_input and source_type:
            st.session_state.retriever = get_retriever_from_source(source_type, source_input)
            if st.session_state.retriever:
                st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
            else:
                st.error("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


    st.divider()
    # --- ì˜ìƒ ì œì‘ ì„¤ì • ì„¹ì…˜ ---
    st.subheader("ğŸ’¡ ì˜ìƒ ì œì‘ ì„¤ì •")

    # ì˜ìƒ ì£¼ì œ ì…ë ¥ í•„ë“œ
    st.session_state.video_topic = st.text_input(
        "ì˜ìƒ ì£¼ì œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì„¸ìš”:",
        value=st.session_state.video_topic # ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜´
    )

    # ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© (ìˆ˜ì • ê°€ëŠ¥) í…ìŠ¤íŠ¸ ì˜ì—­
    st.session_state.edited_script_content = st.text_area(
        "ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© (ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”):",
        value=st.session_state.edited_script_content, # ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜´
        height=300
    )
    
    # ìŒì„± í¬í•¨ ì—¬ë¶€ ì„ íƒ
    include_voice = st.checkbox("ì˜ìƒì— ìŒì„± í¬í•¨", value=st.session_state.include_voice)
    st.session_state.include_voice = include_voice

    if include_voice:
        # TTS í…œí”Œë¦¿ ì„ íƒ
        selected_tts_template = st.selectbox(
            "ìŒì„± í…œí”Œë¦¿ ì„ íƒ",
            options=list(TTS_TEMPLATES.keys()),
            index=list(TTS_TEMPLATES.keys()).index(st.session_state.selected_tts_template)
        )
        st.session_state.selected_tts_template = selected_tts_template

    # ìë§‰ í…œí”Œë¦¿ ì„ íƒ
    selected_subtitle_template = st.selectbox(
        "ìë§‰ í…œí”Œë¦¿ ì„ íƒ",
        options=list(SUBTITLE_TEMPLATES.keys()),
        index=list(SUBTITLE_TEMPLATES.keys()).index(st.session_state.selected_subtitle_template)
    )
    st.session_state.selected_subtitle_template = selected_subtitle_template

    # BGM íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ ì‚¬í•­)
    uploaded_bgm_file = st.file_uploader("BGM íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ ì‚¬í•­, .mp3)", type=["mp3"])
    if uploaded_bgm_file:
        bgm_save_path = "assets/bgm.mp3" # ì„ì‹œ ì €ì¥ ê²½ë¡œ
        os.makedirs(os.path.dirname(bgm_save_path), exist_ok=True)
        with open(bgm_save_path, "wb") as f:
            f.write(uploaded_bgm_file.read())
        st.session_state.bgm_path = bgm_save_path
        st.success("BGM íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ!")
    else:
        st.session_state.bgm_path = None


    if st.button("ì˜ìƒ ë§Œë“¤ê¸°"):
        # ì‚¬ìš©ìê°€ ìˆ˜ì •í•œ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©ê³¼ ì£¼ì œë¥¼ ì‚¬ìš©
        final_script_for_video = st.session_state.edited_script_content
        final_topic_for_video = st.session_state.video_topic

        if not final_script_for_video.strip():
            st.error("ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìƒì„±í•´ì£¼ì„¸ìš”.")
            st.stop()
        if not final_topic_for_video.strip():
            st.error("ì˜ìƒ ì£¼ì œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()

        with st.spinner("âœ¨ ì˜ìƒ ì œì‘ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # --- 0-1. ì¶”ì¶œëœ í† í”½ì„ ì˜ì–´ë¡œ ë²ˆì—­ (GoogleTranslator ì‚¬ìš©) ---
                st.write("ğŸŒ ì´ë¯¸ì§€ ê²€ìƒ‰ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­ ì¤‘...")
                image_query_english = ""
                try:
                    translator = GoogleTranslator(source='ko', target='en')
                    image_query_english = translator.translate(final_topic_for_video)
                    st.success(f"ì´ë¯¸ì§€ ê²€ìƒ‰ì–´ ë²ˆì—­ ì™„ë£Œ (ì˜ì–´): '{image_query_english}'")
                except Exception as e:
                    st.warning(f"ì´ë¯¸ì§€ ê²€ìƒ‰ì–´ ë²ˆì—­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í•œêµ­ì–´ ê²€ìƒ‰ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
                    image_query_english = final_topic_for_video
                image_query_final = image_query_english 

                audio_path = None
                segments = []

                if st.session_state.include_voice:
                    # --- 1. Text-to-Speech (TTS) ìƒì„± ---
                    audio_output_dir = "assets"
                    os.makedirs(audio_output_dir, exist_ok=True)
                    audio_path = os.path.join(audio_output_dir, "generated_audio.mp3")
                    
                    st.write("ğŸ—£ï¸ ìŒì„± íŒŒì¼ ìƒì„± ì¤‘...")
                    generate_tts(
                        text=final_script_for_video,
                        save_path=audio_path,
                        template_name=st.session_state.selected_tts_template
                    )
                    st.success(f"ìŒì„± íŒŒì¼ ìƒì„± ì™„ë£Œ: {audio_path}")

                    # --- 2. Audio Transcription (ASR) ë° Subtitle (ASS) íŒŒì¼ ìƒì„± ---
                    subtitle_output_dir = "assets"
                    os.makedirs(subtitle_output_dir, exist_ok=True)
                    ass_path = os.path.join(subtitle_output_dir, "generated_subtitle.ass")

                    st.write("ğŸ“ ìë§‰ ìƒì„±ì„ ìœ„í•œ ìŒì„± ë¶„ì„ ì¤‘...")
                    segments = transcribe_audio_with_timestamps(audio_path)
                    generate_ass_subtitle(
                        segments=segments,
                        ass_path=ass_path,
                        template_name=st.session_state.selected_subtitle_template
                    )
                    st.success(f"ìë§‰ íŒŒì¼ ìƒì„± ì™„ë£Œ: {ass_path}")
                else: # ìŒì„±ì´ ì—†ëŠ” ê²½ìš°
                    st.write("ìŒì„± ì—†ì´ ìë§‰ê³¼ ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.")

                    # ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
                    # . ? ! ë¡œ ëë‚˜ëŠ” ê²½ìš°ë¥¼ ë¬¸ì¥ ëìœ¼ë¡œ ê°„ì£¼í•˜ê³ , ê·¸ ë’¤ì˜ ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
                    sentences = re.split(r'(?<=[.?!])\s*', final_script_for_video.strip())
                    # ë¶„í•  í›„ ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ë¬¸ìì—´ ì œê±°
                    sentences = [s.strip() for s in sentences if s.strip()]

                    # ìŠ¤í¬ë¦½íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¬¸ì¥ìœ¼ë¡œ ì œëŒ€ë¡œ ë¶„í• ë˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ê°„ì£¼
                    if not sentences:
                        sentences = [final_script_for_video.strip()] # ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ

                    # ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ì— ê¸°ë°˜í•œ ì´ ì˜ˆìƒ ì§€ì† ì‹œê°„ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
                    words_per_minute = 150 # ë¶„ë‹¹ ë‹¨ì–´ ìˆ˜ (í‰ê· ì ì¸ ì½ê¸° ì†ë„)
                    total_script_words = len(final_script_for_video.split())
                    total_estimated_duration_seconds = (total_script_words / words_per_minute) * 60

                    if total_estimated_duration_seconds < 5: # ë„ˆë¬´ ì§§ì€ ì˜ìƒ ë°©ì§€ (ìµœì†Œ 5ì´ˆ)
                        total_estimated_duration_seconds = 5

                    # ê° ë¬¸ì¥ì˜ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì‹œê°„ í• ë‹¹
                    total_chars = sum(len(s) for s in sentences) # ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ì˜ ì´ ê¸€ì ìˆ˜
                    current_time = 0.0 # í˜„ì¬ ì‹œê°„ (ëˆ„ì )
                    segments = [] # ìµœì¢… segments ë¦¬ìŠ¤íŠ¸

                    for sentence_text in sentences:
                        # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥(ì˜ˆ: "ë„¤.")ì— ëŒ€í•œ ìµœì†Œ ì§€ì† ì‹œê°„ ì„¤ì •
                        min_segment_duration = 1.5 # ì´ˆ

                        # ë¬¸ì¥ ê¸¸ì´ì— ë¹„ë¡€í•œ ì§€ì† ì‹œê°„ ê³„ì‚°
                        if total_chars > 0: # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ ë°©ì§€
                            proportion = len(sentence_text) / total_chars
                            segment_duration = total_estimated_duration_seconds * proportion
                        else: # ìŠ¤í¬ë¦½íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ íŠ¹ìˆ˜í•œ ê²½ìš° (ì´ ê²½ìš°ëŠ” ê±°ì˜ ì—†ê² ì§€ë§Œ ì•ˆì „ì¥ì¹˜)
                            segment_duration = total_estimated_duration_seconds / len(sentences)

                        # ìµœì†Œ ì§€ì† ì‹œê°„ ë³´ì¥
                        segment_duration = max(min_segment_duration, segment_duration)

                        segments.append({
                            "start": current_time,
                            "end": current_time + segment_duration,
                            "text": sentence_text
                        })
                        current_time += segment_duration

                    # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ì˜ 'end' ì‹œê°„ì„ ì‹¤ì œ ëˆ„ì ëœ ìµœì¢… ì‹œê°„ìœ¼ë¡œ ë§ì¶¤ (ì •í™•ì„±)
                    if segments:
                        segments[-1]["end"] = current_time 

                    subtitle_output_dir = "assets"
                    os.makedirs(subtitle_output_dir, exist_ok=True)
                    ass_path = os.path.join(subtitle_output_dir, "generated_subtitle.ass")

                    st.write("ğŸ“ ìë§‰ íŒŒì¼ ìƒì„± ì¤‘...")
                    generate_ass_subtitle(
                        segments=segments,
                        ass_path=ass_path,
                        template_name=st.session_state.selected_subtitle_template
                    )
                    st.success(f"ìë§‰ íŒŒì¼ ìƒì„± ì™„ë£Œ: {ass_path}")

                # --- 3. ì´ë¯¸ì§€ ìƒì„± ---
                # ìŒì„±ì´ ì—†ì–´ë„ ì´ë¯¸ì§€ëŠ” í•„ìš”í•˜ë¯€ë¡œ í•­ìƒ ìƒì„±
                num_images = max(3, len(segments)) if segments else 3 # ìµœì†Œ 3ì¥ ë˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ë§Œí¼
                image_output_dir = "assets"
                os.makedirs(image_output_dir, exist_ok=True)
                
                st.write(f"ğŸ–¼ï¸ '{image_query_final}' ê´€ë ¨ ì´ë¯¸ì§€ {num_images}ì¥ ìƒì„± ì¤‘...")
                image_paths = generate_images_for_topic(image_query_final, num_images)
                
                if not image_paths:
                    st.warning("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    default_image_path = "assets/default_image.jpg"
                    if not os.path.exists(default_image_path):
                        try:
                            print("Downloading a placeholder image as default_image.jpg is not found.")
                            generic_image_url = "https://images.pexels.com/photos/936043/pexels-photo-936043.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=2" # Example URL
                            image_data = requests.get(generic_image_url).content
                            with open(default_image_path, "wb") as f:
                                f.write(image_data)
                            print(f"âœ… Placeholder image saved to: {default_image_path}")
                        except Exception as img_dl_e:
                            st.error(f"ê¸°ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œì—ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {img_dl_e}")
                            st.stop()
                    image_paths = [default_image_path] 
                    
                st.success(f"ì´ë¯¸ì§€ {len(image_paths)}ì¥ ìƒì„± ì™„ë£Œ.")

                # --- 4. ë¹„ë””ì˜¤ ìƒì„± (ìë§‰ ì œì™¸) ---
                video_output_dir = "assets"
                os.makedirs(video_output_dir, exist_ok=True)
                temp_video_path = os.path.join(video_output_dir, "temp_video.mp4")
                final_video_path = os.path.join(video_output_dir, "final_video_with_subs.mp4")

                st.write("ğŸ¬ ë¹„ë””ì˜¤ í´ë¦½ ì¡°í•© ë° ì˜¤ë””ì˜¤ í†µí•© ì¤‘...")
                created_video_path = create_video_with_segments(
                    image_paths=image_paths,
                    segments=segments, # segmentsë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì§€ì† ì‹œê°„ ê²°ì •
                    audio_path=audio_path if st.session_state.include_voice else None, # ìŒì„± ë¯¸í¬í•¨ ì‹œ None ì „ë‹¬
                    topic_title=final_topic_for_video,
                    include_topic_title=True,
                    bgm_path=st.session_state.bgm_path,
                    save_path=temp_video_path,
                )
                st.success(f"ê¸°ë³¸ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {created_video_path}")

                # --- 5. ë¹„ë””ì˜¤ì— ìë§‰ ì¶”ê°€ ---
                st.write("ğŸ“ ë¹„ë””ì˜¤ì— ìë§‰ ì¶”ê°€ ì¤‘...")
                final_video_with_subs_path = add_subtitles_to_video(
                    input_video_path=created_video_path,
                    ass_path=ass_path,
                    output_path=final_video_path
                )
                st.success(f"âœ… ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ: {final_video_with_subs_path}")

                # --- 6. ê²°ê³¼ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ ---
                st.video(final_video_with_subs_path)
                with open(final_video_with_subs_path, "rb") as file:
                    st.download_button(
                        label="ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                        data=file,
                        file_name="generated_multimodal_video.mp4",
                        mime="video/mp4"
                    )
                
                # Clean up temporary video file (optional)
                if os.path.exists(temp_video_path):
                    os.remove(temp_video_path)

            except Exception as e:
                st.error(f"âŒ ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)

    st.divider()
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for i, message in enumerate(st.session_state["messages"]):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message["role"] == "assistant" and "sources" in message and message["sources"]:
            with st.expander("ì°¸ê³ í•œ ì¶œì²˜ ë³´ê¸°"):
                for j, source in enumerate(message["sources"]):
                    st.info(f"**ì¶œì²˜ {j+1}**\n\n{source.page_content}")
                    st.divider()

user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.session_state.last_user_query = user_input
    st.chat_message("user").write(user_input)

    try:
        chat_history = [
            HumanMessage(content=msg["content"]) if msg["role"] == "user" 
            else AIMessage(content=msg["content"])
            for msg in st.session_state.messages[:-1]
        ]
        
        if st.session_state.retriever:
            with st.chat_message("assistant"):
                with st.spinner("ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    retriever = st.session_state.retriever
                    source_documents = retriever.get_relevant_documents(user_input)
                    document_chain = get_document_chain(st.session_state.system_prompt)
                    
                    ai_answer = document_chain.invoke({
                        "input": user_input,
                        "chat_history": chat_history,
                        "context": source_documents
                    })
                    
                    st.markdown(ai_answer)
                    
                    st.session_state.messages.append({
                        "role": "assistant", "content": ai_answer, "sources": source_documents
                    })
                    
                    if source_documents:
                        with st.expander("ì°¸ê³ í•œ ì¶œì²˜ ë³´ê¸°"):
                            for i, source in enumerate(source_documents):
                                st.info(f"**ì¶œì²˜ {i+1}**\n\n{source.page_content}")
                                st.divider()
            # ì±—ë´‡ì´ ë‹µë³€ì„ ìƒì„±í•œ í›„, ì‚¬ì´ë“œë°”ì˜ ìŠ¤í¬ë¦½íŠ¸ì™€ ì£¼ì œ í•„ë“œë¥¼ ìë™ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.
            st.session_state.edited_script_content = ai_answer
            # ì±—ë´‡ ë‹µë³€ì—ì„œ ìë™ìœ¼ë¡œ ì£¼ì œë¥¼ ì¶”ì¶œí•˜ì—¬ í•„ë“œì— ì±„ì›ë‹ˆë‹¤.
            with st.spinner("ë‹µë³€ì—ì„œ ì˜ìƒ ì£¼ì œë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œ ì¤‘..."):
                topic_extraction_prompt = f"""ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ 2-3ê°œì˜ ê°„ê²°í•œ í‚¤ì›Œë“œ ë˜ëŠ” ì•„ì£¼ ì§§ì€ êµ¬ë¬¸(ìµœëŒ€ 10ë‹¨ì–´)ìœ¼ë¡œ ë©”ì¸ ì£¼ì œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. í‚¤ì›Œë“œ/êµ¬ë¬¸ë§Œ ì‘ë‹µí•˜ì„¸ìš”.

                ìŠ¤í¬ë¦½íŠ¸:
                {ai_answer}

                í‚¤ì›Œë“œ/ì£¼ì œ:"""
                topic_llm_chain = get_default_chain(system_prompt="ë‹¹ì‹ ì€ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ìš©í•œ ì¡°ìˆ˜ì…ë‹ˆë‹¤.")
                extracted_topic_for_ui = topic_llm_chain.invoke({"question": topic_extraction_prompt, "chat_history": []}).strip()
                if extracted_topic_for_ui:
                    st.session_state.video_topic = extracted_topic_for_ui 
                else:
                    st.session_state.video_topic = user_input # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ì ì§ˆë¬¸ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
            st.rerun() # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ rerun
        else:
            chain = get_default_chain(st.session_state.system_prompt)
            with st.chat_message("assistant"):
                container = st.empty()
                ai_answer = ""
                for token in chain.stream({"question": user_input, "chat_history": chat_history}):
                    ai_answer += token
                    container.markdown(ai_answer)
                st.session_state.messages.append({"role": "assistant", "content": ai_answer, "sources": []})
            # ì±—ë´‡ì´ ë‹µë³€ì„ ìƒì„±í•œ í›„, ì‚¬ì´ë“œë°”ì˜ ìŠ¤í¬ë¦½íŠ¸ì™€ ì£¼ì œ í•„ë“œë¥¼ ìë™ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.
            st.session_state.edited_script_content = ai_answer
            with st.spinner("ë‹µë³€ì—ì„œ ì˜ìƒ ì£¼ì œë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œ ì¤‘..."):
                topic_extraction_prompt = f"""ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ 2-3ê°œì˜ ê°„ê²°í•œ í‚¤ì›Œë“œ ë˜ëŠ” ì•„ì£¼ ì§§ì€ êµ¬ë¬¸(ìµœëŒ€ 10ë‹¨ì–´)ìœ¼ë¡œ ë©”ì¸ ì£¼ì œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. í‚¤ì›Œë“œ/êµ¬ë¬¸ë§Œ ì‘ë‹µí•˜ì„¸ìš”.

                ìŠ¤í¬ë¦½íŠ¸:
                {ai_answer}

                í‚¤ì›Œë“œ/ì£¼ì œ:"""
                topic_llm_chain = get_default_chain(system_prompt="ë‹¹ì‹ ì€ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ìš©í•œ ì¡°ìˆ˜ì…ë‹ˆë‹¤.")
                extracted_topic_for_ui = topic_llm_chain.invoke({"question": topic_extraction_prompt, "chat_history": []}).strip()
                if extracted_topic_for_ui:
                    st.session_state.video_topic = extracted_topic_for_ui + "\n"
                else:
                    st.session_state.video_topic = user_input + "\n" # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ì ì§ˆë¬¸ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
            st.rerun() # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ rerun
    except Exception as e:
        st.chat_message("assistant").error(f"ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: {e}")
        st.session_state.messages.pop()