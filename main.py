# main.py

import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage
from rag_pipeline import get_retriever_from_source, get_document_chain, get_default_chain, get_shorts_script_generation_prompt, generate_topic_insights
from web_ingest import full_web_ingest
from image_generator import generate_images_for_topic
from elevenlabs_tts import generate_tts, TTS_TEMPLATES
from whisper_asr import transcribe_audio_with_timestamps, generate_ass_subtitle, SUBTITLE_TEMPLATES
from video_maker import create_video_with_segments, add_subtitles_to_video
from deep_translator import GoogleTranslator
import os
import requests # ê¸°ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ ì¶”ê°€
import re
import json # for constraints parsing

# API í‚¤ ë¡œë“œ
load_dotenv()

# --- ì•± ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="Multimodal RAG Chatbot", page_icon="ğŸ¤–")
st.title("ğŸ¤– ë©€í‹°ëª¨ë‹¬ íŒŒì¼/URL ë¶„ì„ RAG ì±—ë´‡")
st.markdown(
    """
ì•ˆë…•í•˜ì„¸ìš”! ì´ ì±—ë´‡ì€ ì›¹ì‚¬ì´íŠ¸ URLì´ë‚˜ ì—…ë¡œë“œëœ íŒŒì¼(PDF, DOCX, TXT)ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤.
"""
)

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "retriever" not in st.session_state:
    st.session_state.retriever = None
if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = "ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì´ì, ìˆí¼(Short-form) ì˜ìƒ ì œì‘ì„ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œì˜ í…ìŠ¤íŠ¸ì™€ í…Œì´ë¸”ì„ ì •í™•íˆ ì´í•´í•˜ê³ , ì§§ê³  ê°„ê²°í•˜ë©° í•µì‹¬ ë‚´ìš©ì„ ë‹´ì€ ì‡¼ì¸  ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì œì‘í•´ì£¼ì„¸ìš”. ìŠ¤í¬ë¦½íŠ¸ ì™¸ì—ëŠ” ì–´ë–¤ ë‹µë³€ë„ í•´ì„œëŠ” ì•ˆë©ë‹ˆë‹¤. ë˜í•œ ë§ˆí¬ë‹¤ìš´ê³¼ ê°™ì€ ê¸°í˜¸ëŠ” ì „ë¶€ ì œê±°í•´ì£¼ì„¸ìš”."
if "last_user_query" not in st.session_state:
    st.session_state.last_user_query = ""
if "video_topic" not in st.session_state:
    st.session_state.video_topic = "" # ì˜ìƒ ì£¼ì œ ì´ˆê¸°í™”
if "edited_script_content" not in st.session_state:
    st.session_state.edited_script_content = "" # ìˆ˜ì • ê°€ëŠ¥í•œ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© ì´ˆê¸°í™”
if "selected_tts_template" not in st.session_state:
    st.session_state.selected_tts_template = "educational"
if "selected_subtitle_template" not in st.session_state:
    st.session_state.selected_subtitle_template = "educational"
if "bgm_path" not in st.session_state:
    st.session_state.bgm_path = None
if "include_voice" not in st.session_state:
    st.session_state.include_voice = True # ìŒì„± í¬í•¨ ì—¬ë¶€ ì´ˆê¸°í™”
if "generated_topics" not in st.session_state:
    st.session_state.generated_topics = []
if "selected_video_topic" not in st.session_state:
    st.session_state.selected_video_topic = ""

# --- ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    st.divider()

    st.subheader("ğŸ‘¨â€ğŸ« ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ ì„¤ì • (ì£¼ì œ ìƒì„±)")
    expert_persona_name = st.text_input("í˜ë¥´ì†Œë‚˜ ì´ë¦„ (ì˜ˆ: êµìœ¡ ì „ë¬¸ê°€)", value="êµìœ¡ ì „ë¬¸ê°€")
    expert_domain = st.text_input("ì „ë¬¸ ë¶„ì•¼ (ì˜ˆ: ìµœì‹  IT íŠ¸ë Œë“œ)", value="ìµœì‹  IT íŠ¸ë Œë“œ")
    expert_audience = st.text_input("ëŒ€ìƒ ë…ì (ì˜ˆ: ì¼ë°˜ì¸, ê°œë°œì)", value="ì¼ë°˜ì¸")
    expert_tone = st.text_input("í†¤ (ì˜ˆ: ì •ë³´ì„±, ìœ ìµí•œ)", value="ì •ë³´ì„±")
    expert_format = st.text_input("ì¶œë ¥ í˜•ì‹ (ì˜ˆ: 10ê°€ì§€ ì£¼ì œ ëª©ë¡)", value="10ê°€ì§€ ì£¼ì œ ëª©ë¡")
    expert_constraints_str = st.text_area("ì¶”ê°€ ì¡°ê±´ (JSON í˜•ì‹)", value='{"ê¸¸ì´": "ìµœëŒ€ 100ì", "í¬í•¨ í‚¤ì›Œë“œ": "ì¸ê³µì§€ëŠ¥, ë¹…ë°ì´í„°"}')

    if st.button("ì£¼ì œ ìƒì„±"):
        try:
            constraints_dict = json.loads(expert_constraints_str)
            topic_prompt = generate_topic_insights(
                persona=expert_persona_name,
                domain=expert_domain,
                audience=expert_audience,
                tone=expert_tone,
                format=expert_format,
                constraints=expert_constraints_str # Pass as string as per function signature
            )
            st.session_state.messages.append(HumanMessage(content=f"**[ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜] ì£¼ì œ ìƒì„± ìš”ì²­:**\n{topic_prompt}"))
            
            with st.spinner("ì£¼ì œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                topic_llm_chain = get_default_chain(system_prompt=expert_persona_name) # Use expert persona as system prompt
                generated_topics_raw = topic_llm_chain.invoke({"question": topic_prompt, "chat_history": []})
                
                # Assuming topics are separated by newlines, split and clean them
                st.session_state.generated_topics = [
                    topic.strip() for topic in generated_topics_raw.split('\n') if topic.strip()
                ]
                
                ai_answer = "ë‹¤ìŒ ì£¼ì œë“¤ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:\n" + "\n".join(st.session_state.generated_topics)
                st.session_state.messages.append(AIMessage(content=ai_answer))
                st.session_state.selected_video_topic = st.session_state.generated_topics[0] if st.session_state.generated_topics else ""
        except json.JSONDecodeError:
            st.error("ì¶”ê°€ ì¡°ê±´ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì£¼ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if st.session_state.generated_topics:
        st.subheader("ğŸ¬ ì½˜í…ì¸  ì œì‘ì í˜ë¥´ì†Œë‚˜ (ìŠ¤í¬ë¦½íŠ¸ ìƒì„±)")
        st.session_state.selected_video_topic = st.selectbox(
            "ìƒì„±ëœ ì£¼ì œ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:", 
            st.session_state.generated_topics,
            index=st.session_state.generated_topics.index(st.session_state.selected_video_topic) 
            if st.session_state.selected_video_topic in st.session_state.generated_topics 
            else 0
        )
        if st.button("ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"):
            if st.session_state.selected_video_topic:
                script_generation_prompt = get_shorts_script_generation_prompt(
                    user_question_content=st.session_state.selected_video_topic,
                    script_persona="ë§¤ë ¥ì ì´ê³  ë°”ì´ëŸ´ì„± ìˆëŠ” ìˆí¼ ë¹„ë””ì˜¤ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ í¬ë¦¬ì—ì´í„°"
                )
                st.session_state.messages.append(HumanMessage(content=f"**[ì½˜í…ì¸  ì œì‘ì í˜ë¥´ì†Œë‚˜] ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ìš”ì²­ (ì£¼ì œ: {st.session_state.selected_video_topic}):**\n{script_generation_prompt}"))
                
                with st.spinner("ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    script_llm_chain = get_default_chain(system_prompt="ë‹¹ì‹ ì€ ìˆí¼ ë¹„ë””ì˜¤ ìŠ¤í¬ë¦½íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")
                    generated_script = script_llm_chain.invoke({"question": script_generation_prompt, "chat_history": []})
                    
                    st.session_state.edited_script_content = generated_script
                    st.session_state.messages.append(AIMessage(content=f"**[ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸]**\n{generated_script}"))
            else:
                st.warning("ë¨¼ì € ì£¼ì œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")


    st.divider()
    st.subheader("ğŸ“ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€ (ê¸°ì¡´ RAG)")
    st.session_state.system_prompt = st.text_area(
        "AIì˜ ì—­í• ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.",
        value=st.session_state.system_prompt,
        height=150
    )

    source_type = st.radio("ë¬¸ì„œ ì†ŒìŠ¤ ì„ íƒ:", ("URL", "Files"))
    source_input = None
    if source_type == "URL":
        source_input = st.text_input("URLì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: https://www.example.com)")
    else:
        source_input = st.file_uploader("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["pdf", "docx", "txt"], accept_multiple_files=True)

    if st.button("ë¬¸ì„œ ì²˜ë¦¬ ë° RAG í™œì„±í™”"):
        if source_input:
            with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                st.session_state.retriever = get_retriever_from_source(source_type, source_input)
            st.success("ë¬¸ì„œ ì²˜ë¦¬ ë° RAG í™œì„±í™” ì™„ë£Œ!")
        else:
            st.warning("URLì„ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

    st.divider()
    st.subheader("ğŸ“¹ ë¹„ë””ì˜¤ ìƒì„± ì„¤ì •")
    st.session_state.edited_script_content = st.text_area(
        "ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì • ê°€ëŠ¥):",
        value=st.session_state.edited_script_content,
        height=200
    )

    st.session_state.video_topic = st.text_input("ì˜ìƒ ì£¼ì œ (ì´ë¯¸ì§€ ìƒì„± í‚¤ì›Œë“œ):", value=st.session_state.video_topic)

    tts_template_options = list(TTS_TEMPLATES.keys())
    st.session_state.selected_tts_template = st.selectbox(
        "ìŒì„± í…œí”Œë¦¿ ì„ íƒ:",
        tts_template_options,
        index=tts_template_options.index(st.session_state.selected_tts_template)
    )

    subtitle_template_options = list(SUBTITLE_TEMPLATES.keys())
    st.session_state.selected_subtitle_template = st.selectbox(
        "ìë§‰ í…œí”Œë¦¿ ì„ íƒ:",
        subtitle_template_options,
        index=subtitle_template_options.index(st.session_state.selected_subtitle_template)
    )

    st.session_state.bgm_path = st.file_uploader("ë°°ê²½ ìŒì•… íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ ì‚¬í•­)", type=["mp3", "wav"])
    if st.session_state.bgm_path:
        # Save the uploaded BGM file to a temporary location
        with open(os.path.join("assets", st.session_state.bgm_path.name), "wb") as f:
            f.write(st.session_state.bgm_path.getbuffer())
        st.session_state.bgm_path = os.path.join("assets", st.session_state.bgm_path.name)
    
    st.session_state.include_voice = st.checkbox("ìŒì„± í¬í•¨", value=st.session_state.include_voice)


# --- ì±— ì¸í„°í˜ì´ìŠ¤ ---
for message in st.session_state.messages:
    if message["role"] == "user":
        with st.chat_message("user"):
            st.markdown(message["content"])
    else:
        with st.chat_message("assistant"):
            st.markdown(message["content"])

user_input = st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš” (ì˜ˆ: ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ 'ìƒì„±í˜• AI'ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜)")

if user_input:
    st.session_state.messages.append(HumanMessage(content=user_input))
    with st.chat_message("user"):
        st.markdown(user_input)

    chat_history = st.session_state.messages
    
    # ì±—ë´‡ ë‹µë³€ ìƒì„± ë¡œì§ (ê¸°ì¡´ RAGì™€ í†µí•©)
    with st.chat_message("assistant"):
        container = st.empty()
        ai_answer = ""
        
        # RAGê°€ í™œì„±í™”ëœ ê²½ìš°
        if st.session_state.retriever:
            retrieval_chain = (
                st.session_state.retriever
                | get_document_chain(st.session_state.system_prompt)
            )
            # Invoke retrieval_chain with proper input for conversation history
            final_llm_question = {"question": user_input, "chat_history": chat_history}
            
            for token in retrieval_chain.stream(final_llm_question):
                ai_answer += token
                container.markdown(ai_answer)
        else:
            # RAGê°€ í™œì„±í™”ë˜ì§€ ì•Šì€ ê²½ìš°, ê¸°ë³¸ ì±—ë´‡ ì²´ì¸ ì‚¬ìš© (ì‚¬ìš©ì ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬)
            chain = get_default_chain(st.session_state.system_prompt)
            for token in chain.stream({"question": user_input, "chat_history": chat_history}):
                ai_answer += token
                container.markdown(ai_answer)

        st.session_state.messages.append({"role": "assistant", "content": ai_answer, "sources": []})
    
    # ì±—ë´‡ì´ ë‹µë³€ì„ ìƒì„±í•œ í›„, ì‚¬ì´ë“œë°”ì˜ ìŠ¤í¬ë¦½íŠ¸ì™€ ì£¼ì œ í•„ë“œë¥¼ ìë™ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.
    st.session_state.edited_script_content = ai_answer
    with st.spinner("ë‹µë³€ì—ì„œ ì˜ìƒ ì£¼ì œë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œ ì¤‘..."):
        topic_extraction_prompt = f"""ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ 2-3ê°œì˜ ê°„ê²°í•œ í‚¤ì›Œë“œ ë˜ëŠ” ì•„ì£¼ ì§§ì€ êµ¬ë¬¸(ìµœëŒ€ 10ë‹¨ì–´)ìœ¼ë¡œ ë©”ì¸ ì£¼ì œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. í‚¤ì›Œë“œ/êµ¬ë¬¸ë§Œ ì‘ë‹µí•˜ì„¸ìš”.

        ìŠ¤í¬ë¦½íŠ¸:
        {ai_answer}

        í‚¤ì›Œë“œ/ì£¼ì œ:"""
        topic_llm_chain = get_default_chain(system_prompt="ë‹¹ì‹ ì€ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ìš©í•œ ì¡°ìˆ˜ì…ë‹ˆë‹¤.")
        extracted_topic_for_ui = topic_llm_chain.invoke({"question": topic_extraction_prompt, "chat_history": []}).strip()
        if extracted_topic_for_ui:
            st.session_state.video_topic = extracted_topic_for_ui


# ë¹„ë””ì˜¤ ìƒì„± ë²„íŠ¼
if st.button("ğŸš€ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘"):
    if not st.session_state.edited_script_content:
        st.error("ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìƒì„±í•´ì£¼ì„¸ìš”.")
    elif not st.session_state.video_topic:
        st.error("ì˜ìƒ ì£¼ì œê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì˜ìƒ ì£¼ì œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì¶”ì¶œí•´ì£¼ì„¸ìš”.")
    else:
        st.subheader("ğŸ¥ ë¹„ë””ì˜¤ ìƒì„± ê²°ê³¼")

        # 1. ìŒì„± ìƒì„±
        audio_path = "assets/audio.mp3"
        if st.session_state.include_voice:
            with st.spinner("ìŒì„±ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                generate_tts(
                    text=st.session_state.edited_script_content,
                    save_path=audio_path,
                    template_name=st.session_state.selected_tts_template
                )
            st.success(f"ìŒì„± ìƒì„± ì™„ë£Œ: {audio_path}")
            st.audio(audio_path)
        else:
            st.info("ìŒì„± ìƒì„±ì„ ê±´ë„ˆë›°ê³  ë°°ê²½ ìŒì•…ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            audio_path = None # ìŒì„±ì„ í¬í•¨í•˜ì§€ ì•Šìœ¼ë©´ audio_pathë¥¼ Noneìœ¼ë¡œ ì„¤ì •

        # 2. ì´ë¯¸ì§€ ìƒì„±
        image_dir = "assets/images"
        os.makedirs(image_dir, exist_ok=True)
        num_images_to_generate = 5 # ì˜ˆì‹œ: 5ì¥ì˜ ì´ë¯¸ì§€ ìƒì„±
        image_paths = []
        with st.spinner(f"{st.session_state.video_topic}ì— ëŒ€í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            generate_images_for_topic(
                query=st.session_state.video_topic,
                num_images=num_images_to_generate,
                start_index=0
            )
            # Pexels APIëŠ” íŒŒì¼ì„ ì§ì ‘ ë°˜í™˜í•˜ì§€ ì•Šê³  ë‹¤ìš´ë¡œë“œ ê²½ë¡œì— ì €ì¥í•˜ë¯€ë¡œ, ì €ì¥ëœ ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            image_paths = [f"assets/image_{i}.jpg" for i in range(num_images_to_generate)]
            
            # ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë¯¸ë¦¬ë³´ê¸°ë¡œ í‘œì‹œ
            for img_path in image_paths:
                if os.path.exists(img_path):
                    st.image(img_path, caption=os.path.basename(img_path), width=150)
        st.success(f"ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {num_images_to_generate}ì¥")

        # 3. ìë§‰ ìƒì„± (ìŒì„±ì´ ìˆì„ ê²½ìš°)
        ass_path = "assets/subtitles.ass"
        segments_for_subtitle = []
        if st.session_state.include_voice and audio_path and os.path.exists(audio_path):
            with st.spinner("ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                segments_for_subtitle = transcribe_audio_with_timestamps(audio_path)
            st.success("ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì™„ë£Œ!")

            with st.spinner("ìë§‰ íŒŒì¼ (.ass) ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                # transcribe_audio_with_timestampsì˜ ê²°ê³¼ê°€ dict-like object (Segment) ì´ë¯€ë¡œ, ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬
                segments_as_dicts = [{"start": seg.start, "end": seg.end, "text": seg.text} for seg in segments_for_subtitle]
                generate_ass_subtitle(
                    segments=segments_as_dicts,
                    ass_path=ass_path,
                    template_name=st.session_state.selected_subtitle_template
                )
            st.success(f"ìë§‰ íŒŒì¼ ìƒì„± ì™„ë£Œ: {ass_path}")
        elif not st.session_state.include_voice:
            st.info("ìŒì„±ì„ í¬í•¨í•˜ì§€ ì•Šì•„ ìë§‰ ìƒì„±ì„ ê±´ë„ˆëœ€ë‹ˆë‹¤.")
        else:
            st.warning("ìŒì„± íŒŒì¼ì´ ì—†ì–´ ìë§‰ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


        # 4. ë¹„ë””ì˜¤ ìƒì„±
        final_video_path = "assets/final_video_with_subs.mp4"
        if image_paths and (st.session_state.include_voice and segments_for_subtitle) or (not st.session_state.include_voice):
            with st.spinner("ìµœì¢… ë¹„ë””ì˜¤ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                created_video_path = create_video_with_segments(
                    script_content=st.session_state.edited_script_content,
                    image_paths=image_paths,
                    audio_path=audio_path,
                    bgm_path=st.session_state.bgm_path,
                    save_path="assets/video_without_subs.mp4" # ìë§‰ ì¶”ê°€ ì „ ì¤‘ê°„ íŒŒì¼
                )
            st.success(f"ê¸°ë³¸ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {created_video_path}")

            # 5. ìë§‰ì´ ìˆëŠ” ê²½ìš° ë¹„ë””ì˜¤ì— ìë§‰ ì¶”ê°€
            if st.session_state.include_voice and os.path.exists(ass_path):
                with st.spinner("ë¹„ë””ì˜¤ì— ìë§‰ì„ ì¶”ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                    add_subtitles_to_video(
                        video_path="assets/video_without_subs.mp4",
                        subtitle_path=ass_path,
                        output_path=final_video_path
                    )
                st.success(f"ìµœì¢… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {final_video_path}")
            else:
                final_video_path = created_video_path # ìë§‰ì´ ì—†ìœ¼ë©´ ì¤‘ê°„ íŒŒì¼ì´ ìµœì¢… íŒŒì¼
                st.info("ìë§‰ì´ ì—†ì–´ ë¹„ë””ì˜¤ì— ìë§‰ì„ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            if os.path.exists(final_video_path):
                st.video(final_video_path)
            else:
                st.error("ìµœì¢… ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error("ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” ë° í•„ìš”í•œ ì´ë¯¸ì§€ ë˜ëŠ” ì˜¤ë””ì˜¤/ìë§‰ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
