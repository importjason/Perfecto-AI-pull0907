import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage
from RAG.rag_pipeline import get_retriever_from_source
from RAG.chain_builder import get_conversational_rag_chain, get_default_chain
from persona import generate_response_from_persona
from image_generator import generate_images_for_topic, generate_videos_for_topic
from elevenlabs_tts import TTS_ELEVENLABS_TEMPLATES, TTS_POLLY_VOICES
from generate_timed_segments import generate_subtitle_from_script, generate_ass_subtitle, SUBTITLE_TEMPLATES, _auto_split_for_tempo, auto_densify_for_subs, _strip_last_punct_preserve_closers, dedupe_adjacent_texts, harden_ko_sentence_boundaries, _build_dense_from_ssml
from video_maker import (
    create_video_with_segments,
    create_video_from_videos,
    add_subtitles_to_video,
    create_dark_text_video
)
from deep_translator import GoogleTranslator
from file_handler import get_documents_from_files
from upload import upload_to_youtube
from best_subtitle_extractor import load_best_subtitles_documents
from text_scraper import get_links, clean_html_parallel, filter_noise
from langchain_core.documents import Document
import os
import requests
import re
import json
import nest_asyncio
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
import math 
from moviepy import AudioFileClip
nest_asyncio.apply()
load_dotenv()

VIDEO_TEMPLATE = "ì˜ìƒ(ì˜ì–´ë³´ì´ìŠ¤+í•œêµ­ì–´ìë§‰Â·ê°€ìš´ë°)"


# ---------- ìœ í‹¸ ----------
def ensure_min_frames(events, fps=30.0, min_frames=2):
    if not events: return events
    tick = 1.0 / float(fps)
    min_dur = tick * max(1, int(min_frames))
    out = []
    for i, e in enumerate(events):
        s = float(e["start"]); ed = float(e["end"])
        if ed - s < min_dur:
            ed = s + min_dur
            if i + 1 < len(events):
                ed = min(ed, float(events[i+1]["start"]) - 0.001)  # ì‚´ì§ ì—¬ìœ 
        out.append({**e, "start": round(s,3), "end": round(ed,3)})
    return out

def drop_or_fix_empty_text(events, merge_if_overlap_or_gap=0.06):
    if not events: return events
    NBSP = "\u00A0"; ASS_NL = r"\N"
    out = []
    for e in events:
        txt = (e.get("text") or "").strip()
        vis = txt.replace(NBSP, "").replace(ASS_NL, "").strip()
        if not vis:
            # ì™„ì „ ë¹ˆ í…ìŠ¤íŠ¸ë§Œ ì œê±°
            continue
        if out and out[-1]["text"] == txt:
            prev_end = float(out[-1]["end"]); cur_start = float(e["start"])
            gap = max(0.0, cur_start - prev_end)
            # ê²¹ì¹˜ê±°ë‚˜ gapì´ ì•„ì£¼ ì§§ì„ ë•Œë§Œ ë³‘í•©
            if gap <= merge_if_overlap_or_gap:
                out[-1]["end"] = max(out[-1]["end"], e["end"])
            else:
                out.append(e)
        else:
            out.append(e)
    return out

def sanitize_ass_text(s: str) -> str:
    """ASSì—ì„œ ë¬¸ì œë  ìˆ˜ ìˆëŠ” ì¤‘ê´„í˜¸ë¥¼ ì´ìŠ¤ì¼€ì´í”„(ìš°ë¦¬ëŠ” override íƒœê·¸ë¥¼ í…ìŠ¤íŠ¸ì— ë„£ì§€ ì•ŠìŒ)."""
    s = (s or "")
    s = s.replace("\\{", "\\{").replace("\\}", "\\}")  # idempotent
    s = s.replace("{", r"\{").replace("}", r"\}")
    return s

def prepare_text_for_ass(text: str, one_line_threshold=12, biline_target=14) -> str:
    t = bind_compounds(text)                 # ê²°í•© í‘œí˜„ ë³´í˜¸
    t = _protect_short_tail_nbsp(t)          # ë§ê¼¬ë¦¬ ë³´í˜¸
    t = lock_oneliner_if_short(t, one_line_threshold)
    t = smart_biline_break(t, biline_target) # í•„ìš”í•œ ê²½ìš°ë§Œ \N ê°•ì œ
    t = sanitize_ass_text(t)
    # ì™„ì „ ê³µë°± ë°©ì§€(ì •ë§ ë¹ˆ ê²½ìš°ëŠ” NBSP í•˜ë‚˜ë¼ë„ ë„£ì–´ í‘œì‹œ ê°•ì œ)
    if not t.strip().replace(NBSP, "").replace(ASS_NL, ""):
        t = NBSP
    return t

ASS_NL = r"\N"

def _visible_len(s: str) -> int:
    # ë˜í•‘ íŒë‹¨ìš© ê¸¸ì´(ê°œëµ). NBSPëŠ” ê³µë°± ì·¨ê¸‰.
    return len((s or "").replace(NBSP, " "))

def lock_oneliner_if_short(text: str, threshold: int = 12) -> str:
    if _visible_len(text) <= threshold:
        return (text or "").replace(" ", NBSP)
    return text

def smart_biline_break(text: str, target: int = 14) -> str:
    raw = (text or "").replace(NBSP, " ")
    if len(raw) <= target * 2:
        return text  # ìë™ ë˜í•‘ì— ë§¡ê¹€

    import re
    candidates = [m.start() for m in re.finditer(r"[ ,Â·/](?!$)", raw)]
    if not candidates:
        # ì¡°ì‚¬ ê²½ê³„
        candidates = [m.end() for m in re.finditer(r"[ì€ëŠ”ì´ê°€ì„ë¥¼ë„ë§Œì˜ì—](?!$)", raw)]

    mid = len(raw) // 2
    pos = None
    if candidates:
        pos = min(candidates, key=lambda i: abs(i - mid))
    else:
        pos = mid

    left = raw[:pos].rstrip()
    right = raw[pos:].lstrip()
    return (left + ASS_NL + right).replace(" ", " ")

NBSP = "\u00A0"

def bind_compounds(
    text: str,
    unit_words=None,        # ìˆ«ì ë’¤ì— ë¶™ëŠ” ë‹¨ìœ„/ì ‘ë¯¸
    counter_words=None,     # ë²ˆ/ìˆ˜/ëª…/ê°œ/ì¹¸/ì°¨ë¡€ ë“± ì¹´ìš´í„°
    bignum_prefixes=None,   # ìˆ˜ì‹­/ìˆ˜ë°±/ìˆ˜ì²œ/ìˆ˜ë§Œ/ìˆ˜ë°±ë§Œ/ìˆ˜ì–µ/ìˆ˜ì¡°...
    user_terms=None         # ì‚¬ìš©ìê°€ ë³´í˜¸í•˜ê³  ì‹¶ì€ êµ¬(ë‚±ë§ ë¬¶ìŒ)
) -> str:
    """
    ë¬¸ì¥ ë‚´ë¶€ì—ì„œ 'ëŠê¸°ë©´ ì–´ìƒ‰í•œ ê²°í•© í‘œí˜„'ì„ ìë™ ê°ì§€í•´ ê³µë°±ì„ NBSPë¡œ ë°”ê¿‰ë‹ˆë‹¤.
    (ì¤„ë°”ê¿ˆ ì•Œê³ ë¦¬ì¦˜ì´ NBSPë¥¼ ë¶„í•  ì§€ì ìœ¼ë¡œ ë³´ì§€ ì•Šì•„ ìì—°ìŠ¤ëŸ¬ìš´ ëŠê¹€ì„ ìœ ë„)

    - ìˆ«ì+ë‹¨ìœ„: 3ìˆ˜, 9ì , 1ë¶„, 30ì´ˆ, 1cm, 1ë§Œ 2ì²œ km, 10ì˜ 120ì œê³±
    - í°ìˆ˜+ë‹¨ìœ„: ìˆ˜ë°±ë§Œ ìˆ˜, ìˆ˜ì²œë§Œ ëª… ...
    - ì´ë¦„+ê°’: í€¸ 9ì , ë£© 5ì , í° 1ì 
    - ì–‘í™”: (ë‹¨ )?í•œ/ë‘/ì„¸/... + ë²ˆ/ìˆ˜/ëª…/ê°œ/ì¹¸/(ì—)
    - ì‚¬ìš©ì ì •ì˜ ìš©ì–´: user_terms=["í•œ ë²ˆì—","ìˆ˜ë°±ë§Œ ìˆ˜"] ë“±
    """
    if not text or text.isspace():
        return text

    unit_words = unit_words or [
        "ìˆ˜","ì ","ë¶„","ì´ˆ","ì¹¸","ë²ˆ","ê°€ì§€","ëª…","ê°œ","ë…„","ë°°","%",
        "km","m","cm","mm","kg","g","mg","â„ƒ","â„‰","Â°"
    ]
    counter_words = counter_words or ["ë²ˆ","ìˆ˜","ê°€ì§€","ëª…","ê°œ","ì¹¸","ì°¨ë¡€"]
    bignum_prefixes = bignum_prefixes or [
        "ìˆ˜ì‹­","ìˆ˜ë°±","ìˆ˜ì²œ","ìˆ˜ë§Œ","ìˆ˜ì‹­ë§Œ","ìˆ˜ë°±ë§Œ","ìˆ˜ì²œë§Œ","ìˆ˜ì–µ","ìˆ˜ì¡°"
    ]
    user_terms = user_terms or []

    t = text

    # 0) ì‚¬ìš©ì ì§€ì • ì–´êµ¬ ë³´í˜¸ (ê·¸ëŒ€ë¡œ ë„£ìœ¼ë©´ ê°€ì¥ ìœ ì—°)
    #    ì˜ˆ: ["í•œ ë²ˆì—", "ìˆ˜ë°±ë§Œ ìˆ˜", "ë‹¨ í•œ ìˆ˜"]
    if user_terms:
        # ê¸´ ì–´êµ¬ë¶€í„° ì¹˜í™˜(ë¶€ë¶„ ì¤‘ë³µ ë°©ì§€)
        for term in sorted(user_terms, key=len, reverse=True):
            safe = term.replace(" ", NBSP)
            # ë‹¨ì–´ ê²½ê³„ ë¬´ì‹œí•˜ê³  ê·¸ëŒ€ë¡œ ì°¾ì•„ ì¹˜í™˜
            t = t.replace(term, safe)

    # 1) 'ì´ë¦„ + ìˆ«ì + (ì |ìˆ˜|ì¹¸|ë¶„|ì´ˆ|%)' íŒ¨í„´ (í€¸ 9ì , ë£© 5ì , í° 1ì )
    #    ì´ë¦„ì€ í•œê¸€/ì˜ë¬¸ ë‹¨ì–´ í•œ ê°œë¡œ ê°€ì •
    name_val = re.compile(
        r"([ê°€-í£A-Za-z]+)\s+(\d+(?:\.\d+)?)\s*(ì |ìˆ˜|ì¹¸|ë¶„|ì´ˆ|%)"
    )
    def _name_val(m):
        return f"{m.group(1)}{NBSP}{m.group(2)}{NBSP}{m.group(3)}"
    t = name_val.sub(_name_val, t)

    # 2) 'ìˆ«ì(ë³µí•©) + ë‹¨ìœ„' íŒ¨í„´ (1ë§Œ 2ì²œ km, 3 ìˆ˜, 30 ì´ˆ, 1 cm ...)
    #    - '1ë§Œ 2ì²œ' ê°™ì´ ë‚´ë¶€ ê³µë°±ë„ NBSPë¡œ
    unit_alt = "|".join(map(re.escape, unit_words))
    num_unit = re.compile(
        rf"((?:\d+(?:\s*[ë§Œì²œë°±ì‹­])?)(?:\s*\d+)*)(?:\s*)({unit_alt})"
    )
    def _num_unit(m):
        left = m.group(1).replace(" ", NBSP)
        return f"{left}{NBSP}{m.group(2)}"
    t = num_unit.sub(_num_unit, t)

    # 3) 'í°ìˆ˜ ì ‘ë‘(ìˆ˜ë°±/ìˆ˜ì²œë§Œ/ìˆ˜ì–µ/ìˆ˜ì¡°...) + ë‹¨ìœ„' (ìˆ˜ë°±ë§Œ ìˆ˜, ìˆ˜ì²œë§Œ ëª…)
    big_alt = "|".join(map(re.escape, bignum_prefixes))
    big_unit = re.compile(rf"({big_alt})\s*({unit_alt})")
    t = big_unit.sub(lambda m: f"{m.group(1)}{NBSP}{m.group(2)}", t)

    # 4) ì§€ìˆ˜ í‘œê¸° '10ì˜ 120ì œê³±'
    expo = re.compile(r"(\d+)\s*ì˜\s*(\d+)\s*ì œê³±")
    t = expo.sub(lambda m: f"{m.group(1)}{NBSP}ì˜{NBSP}{m.group(2)}{NBSP}ì œê³±", t)

    # 5) ì–‘í™” í‘œí˜„ '(ë‹¨ )?í•œ/ë‘/ì„¸/... + ë²ˆ/ìˆ˜/ê°€ì§€/ëª…/ê°œ/ì¹¸ (+ì—)'
    quant_num = "(í•œ|ë‘|ì„¸|ë„¤|ë‹¤ì„¯|ì—¬ì„¯|ì¼ê³±|ì—¬ëŸ|ì•„í™‰|ì—´)"
    counter_alt = "|".join(map(re.escape, counter_words))
    quant = re.compile(rf"(ë‹¨\s+)?{quant_num}\s+({counter_alt})(ì—)?")
    def _quant(m):
        pre = (m.group(1) or "").replace(" ", NBSP)  # "ë‹¨ " -> "ë‹¨&nbsp;"
        core = f"{m.group(2)}{NBSP}{m.group(3)}"     # "í•œ ë²ˆ"
        tail = f"{NBSP}{m.group(4)}" if m.group(4) else ""
        return f"{pre}{core}{tail}"
    t = quant.sub(_quant, t)

    # 6) ê³µë°± ì •ë¦¬(ì´ì¤‘ ì´ìƒ -> ë‹¨ì¼), ë¬¸ë‘/ë¬¸ë¯¸ ê³µë°± ì œê±° (NBSPëŠ” ìœ ì§€)
    t = re.sub(r"[ \t]{2,}", " ", t).strip()
    return t

def build_image_paths_for_dense_segments(segments_for_video, persona_text: str):
    if "seen_photo_ids" not in st.session_state:
        st.session_state.seen_photo_ids = set()
    if "query_page_cursor_img" not in st.session_state:
        st.session_state.query_page_cursor_img = {}

    sentence_units = [s.get('text', '') for s in segments_for_video]
    per_sentence_queries = get_scene_keywords_batch(sentence_units, persona_text)
    for i, q in enumerate(per_sentence_queries, start=1):
        st.write(f"ğŸ§© ì´˜ì´˜ì¡°ê° {i} í‚¤ì›Œë“œ: {q}")

    def _img_search_once(q: str, idx: int, page: int):
        try:
            paths, ids = generate_images_for_topic(
                q, 1,
                start_index=idx,
                page=page,
                exclude_ids=st.session_state.seen_photo_ids,
                return_ids=True
            )
        except TypeError:
            paths = generate_images_for_topic(q, 1, start_index=idx)
            ids = []
        if paths:
            if ids:
                st.session_state.seen_photo_ids.update(ids)
            return _save_unique_image(paths[0], idx)
        return None

    def _normalize_scene_query(raw: str) -> str:
        import re
        if not raw: return ""
        s = raw.strip()
        s = re.sub(r'(?i)^(here are .*?:)\s*', '', s)
        s = re.sub(r'(?i)^(keywords?|í‚¤ì›Œë“œ)\s*:\s*', '', s)
        s = s.replace("\n", " ").replace("\r", " ")
        s = re.sub(r'["â€œâ€â€˜â€™\'`]+', '', s)
        s = re.sub(r'[^A-Za-z\uAC00-\uD7A30-9 ,\-./Â°%]+', ' ', s)
        s = re.sub(r'\s*,\s*', ',', s)
        s = re.sub(r'\s*\.\s*', '.', s)
        s = re.sub(r'\s{2,}', ' ', s).strip(' ,').strip()
        parts = [p.strip() for p in s.split(',') if p.strip()]
        if parts: s = ', '.join(parts[:3])
        return s[:90].rstrip(' ,')

    def _fetch_one_image(q: str, idx: int, page_tries: int = 4):
        base_pg = st.session_state.query_page_cursor_img.get(q, 1)
        for step in range(page_tries):
            pg = base_pg + step
            got = _img_search_once(q, idx, pg)
            if got:
                st.session_state.query_page_cursor_img[q] = pg + 1
                return got
        if "," in q:
            for piece in [p.strip() for p in q.split(",") if p.strip()]:
                base_pg2 = st.session_state.query_page_cursor_img.get(piece, 1)
                for step in range(page_tries):
                    pg = base_pg2 + step
                    got = _img_search_once(piece, idx, pg)
                    if got:
                        st.session_state.query_page_cursor_img[piece] = pg + 1
                        return got
        fb = _normalize_scene_query(q)
        if fb and fb != q:
            base_pg3 = st.session_state.query_page_cursor_img.get(fb, 1)
            for step in range(page_tries):
                pg = base_pg3 + step
                got = _img_search_once(fb, idx, pg)
                if got:
                    st.session_state.query_page_cursor_img[fb] = pg + 1
                    return got
        return None

    image_paths = []
    target_len = len(segments_for_video)
    for idx, q in enumerate(per_sentence_queries, start=1):
        st.write(f"ğŸ–¼ï¸ ì´˜ì´˜ì¡°ê° {idx} ê²€ìƒ‰: {q}")
        path = _fetch_one_image(q, idx, page_tries=4)
        image_paths.append(path)

    if len(image_paths) < target_len:
        last = image_paths[-1] if image_paths else None
        image_paths += [last] * (target_len - len(image_paths))
    elif len(image_paths) > target_len:
        image_paths = image_paths[:target_len]

    st.success(f"ì´ë¯¸ì§€ {sum(1 for p in image_paths if p)}ì¥ í™•ë³´ / ì´ {target_len}ì¡°ê°")
    return image_paths

def enforce_reading_speed_non_merging(events, min_cps=11.0, floor=0.60, ceiling=None, margin=0.02):
    """
    ìë§‰ì„ 'í•©ì¹˜ì§€' ì•Šê³ , ê°€ëŠ¥í•œ ë²”ìœ„ì—ì„œë§Œ endë¥¼ ëŠ˜ë ¤
    - ê¸€ììˆ˜/ì½ê¸°ì†ë„ ê¸°ë°˜ ìµœì†Œ ë…¸ì¶œì‹œê°„ ë³´ì¥
    - ë‹¤ìŒ cueì˜ ì‹œì‘ì€ ì¹¨ë²”í•˜ì§€ ì•ŠìŒ
    """
    if not events:
        return events
    out = []
    for i, e in enumerate(events):
        s  = float(e["start"])
        ed = float(e["end"])
        text = (e.get("text") or "").strip()
        need = max(floor, (len(text) / max(min_cps, 1e-6)) if text else floor)
        target_end = s + need
        # ë‹¤ìŒ cue ì‹œì‘ ì§ì „ê¹Œì§€ë§Œ í™•ì¥
        if i + 1 < len(events):
            next_s = float(events[i+1]["start"])
            ed = min(max(ed, target_end), next_s - margin)
        else:
            ed = max(ed, target_end)
        if ceiling is not None:
            ed = min(ed, s + float(ceiling))
        if ed < s + 0.02:
            ed = s + 0.02
        out.append({**e, "start": round(s, 3), "end": round(ed, 3)})
    return out

def _protect_short_tail_nbsp(text: str) -> str:
    """
    'ë³´ë³‘ ê°™ì£ ?' ê°™ì€ ê¼¬ë¦¬ê°€ ë‹¤ìŒ ì¤„ë¡œ ë–¨ì–´ì§€ì§€ ì•Šë„ë¡,
    ê¼¬ë¦¬ ì• ê³µë°±ì„ NBSPë¡œ ì¹˜í™˜.
    """
    NBSP = "\u00A0"
    # í•œ/ë‘ ë‹¨ì–´ ê¼¬ë¦¬ íŒ¨í„´ë“¤
    TAILS = [
        r"ê°™ì£ \?", r"ê·¸ë ‡ì£ \?", r"ê·¸ì£ \?", r"ê·¸ì£ ",
        r"ì´ì£ \?", r"ì´ì£ ", r"ì£ \?", r"ì£ ",
        r"ì…ë‹ˆë‹¤", r"ì˜ˆìš”", r"ì´ì—ìš”", r"ì´ë‹¤", r"ë‹¤$"
    ]
    pat = re.compile(r"\s+(?=(" + "|".join(TAILS) + r"))")
    return pat.sub(NBSP, (text or "").strip())

def apply_nbsp_tails(events):
    return [{**e, "text": _protect_short_tail_nbsp(e.get("text") or "")} for e in events]

def quantize_events(events, fps=24.0):
    """ìë§‰ ì‹œê°„ì„ ë¹„ë””ì˜¤ í”„ë ˆì„ ê²©ìì— ë§ì¶° ìŠ¤ëƒ…."""
    if not events: return events
    tick = 1.0 / float(fps)
    out, prev_end = [], None
    for e in events:
        s  = round(float(e["start"]) / tick) * tick
        ed = round(float(e["end"])   / tick) * tick
        if prev_end is not None and s < prev_end:
            s = prev_end
        if ed <= s:
            ed = s + tick
        out.append({**e, "start": round(s, 3), "end": round(ed, 3)})
        prev_end = ed
    return out

def clamp_no_overlap(events, margin=0.05):
    """
    ê° cueì˜ endê°€ ë°˜ë“œì‹œ ë‹¤ìŒ cue start - margin ì´í•˜ê°€ ë˜ë„ë¡ í´ë¨í”„.
    ë³‘í•©/í…ìŠ¤íŠ¸ ë³€ê²½ ì—†ìŒ. ì‹œê°„ë§Œ ì¡°ì •.
    """
    if not events: 
        return events
    out = []
    n = len(events)
    for i, e in enumerate(events):
        s = float(e["start"])
        ed = float(e["end"])
        if i + 1 < n:
            next_s = float(events[i+1]["start"])
            ed = min(ed, next_s - margin)  # ë‹¤ìŒ cue ì‹œì‘ë³´ë‹¤ ì¡°ê¸ˆ(=margin) ì¼ì° ëë‚´ê¸°
        # ë„ˆë¬´ ì§§ì•„ì ¸ë„ 20msëŠ” ë³´ì¥
        if ed < s + 0.02:
            ed = s + 0.02
        out.append({**e, "start": round(s, 3), "end": round(ed, 3)})
    # ë‹¨ì¡°ì„± ìµœì¢… ë³´ì •
    for i in range(n - 1):
        if out[i]["end"] > out[i+1]["start"] - margin:
            out[i]["end"] = max(out[i]["start"] + 0.02, out[i+1]["start"] - margin)
    return out

def enforce_min_duration_non_merging(events, min_dur=0.35, margin=0.05):
    """
    cueë¥¼ ë³‘í•©í•˜ì§€ ì•Šê³  'ê°€ëŠ¥í•œ ë²”ìœ„ì—ì„œë§Œ' ê¸¸ì´ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.
    ë‹¤ìŒ cueì˜ startë¥¼ ì¹¨ë²”í•˜ì§€ ì•Šë„ë¡ marginì„ ë‚¨ê¸°ê³  í™•ì¥.
    """
    if not events:
        return events
    out = []
    for i, e in enumerate(events):
        s, ed = float(e["start"]), float(e["end"])
        dur = ed - s
        if dur < min_dur:
            target = s + min_dur
            if i + 1 < len(events):
                max_end = float(events[i+1]["start"]) - margin
                ed = min(target, max_end)
            else:
                ed = target
        out.append({**e, "start": round(s, 3), "end": round(ed, 3)})
    # ë§ˆì§€ë§‰ìœ¼ë¡œ ê²¹ì¹¨ ë°©ì§€
    return clamp_no_overlap(out, margin=margin)

def enforce_min_duration(segs, min_dur=0.35):
    out = []
    cur = None
    for s in segs:
        if cur is None:
            cur = dict(s); continue
        if (cur["end"] - cur["start"]) < min_dur:
            cur["end"]  = s["end"]
            cur["text"] = (cur["text"] + " " + s["text"]).strip()
        else:
            out.append(cur); cur = dict(s)
    if cur: out.append(cur)
    if len(out) >= 2 and (out[-1]["end"] - out[-1]["start"]) < min_dur:
        out[-2]["end"]  = out[-1]["end"]
        out[-2]["text"] = (out[-2]["text"] + " " + out[-1]["text"]).strip()
        out.pop()
    return out

def _tokenize_words_for_kr_en(text: str):
    """í•œ/ì˜ í˜¼í•© ë¬¸ì¥ì„ ë‹¨ì–´(ë˜ëŠ” ë©ì–´ë¦¬)+ë¬¸ì¥ë¶€í˜¸ ìˆ˜ì¤€ìœ¼ë¡œ í† í°í™”."""
    import re
    tokens = re.findall(r'[\uAC00-\uD7A3A-Za-z0-9]+|[^\s]', text or "")
    merged = []
    for t in tokens:
        if re.match(r'^[^\uAC00-\uD7A3A-Za-z0-9]+$', t) and merged:
            merged[-1] += t
        else:
            merged.append(t)
    return merged

def densify_subtitles_by_words(segments, target_min_events: int):
    """
    ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë” ì˜ê²Œ ìª¼ê°œì–´ 'í•œ í™”ë©´ì— ë¬¸ë‹¨ì´ ì™•ì°½' ëœ¨ëŠ” í˜„ìƒ ë°©ì§€.
    ì˜¤ë””ì˜¤ íƒ€ì´ë°ì€ ìœ ì§€í•˜ê³ , ê° ì„¸ê·¸ë¨¼íŠ¸ ë‚´ë¶€ì—ì„œ ê¸€ì ê¸¸ì´ ë¹„ìœ¨ë¡œ ì‹œê°„ ë°°ë¶„.
    """
    import re
    total_tokens = 0
    per_seg_tokens = []
    for s in segments:
        toks = _tokenize_words_for_kr_en(s['text'])
        per_seg_tokens.append(toks)
        total_tokens += len(toks)

    if total_tokens == 0:
        return segments

    desired_events = max(target_min_events, len(segments))
    chunk_size = max(1, min(6, math.ceil(total_tokens / desired_events)))

    dense = []
    for s, toks in zip(segments, per_seg_tokens):
        if not toks:
            dense.append(s)
            continue
        seg_start, seg_end = s['start'], s['end']
        seg_dur = max(0.01, seg_end - seg_start)
        n_chunks = math.ceil(len(toks) / chunk_size)
        t0 = seg_start
        base_len = max(1, len("".join(toks)))
        for i in range(n_chunks):
            part = toks[i*chunk_size:(i+1)*chunk_size]
            if not part: 
                continue
            is_kor = bool(re.search(r'[\uAC00-\uD7A3]', "".join(part)))
            text = ('' if is_kor else ' ').join(part).strip()
            part_ratio = len("".join(part)) / base_len
            dur = seg_dur * part_ratio
            t1 = t0 + dur
            if i == n_chunks - 1:
                t1 = seg_end
            dense.append({'start': t0, 'end': t1, 'text': text})
            t0 = t1
    return dense

def coalesce_segments_for_videos(segments, clip_count: int):
    """
    ì˜ìƒì´ ì ì„ ë•Œ, ì—°ì† ì„¸ê·¸ë¨¼íŠ¸ë¥¼ clip_countê°œ êµ¬ê°„ìœ¼ë¡œ ë³‘í•©í•´
    ê° ì˜ìƒ í´ë¦½ì´ ë§¡ì„ êµ¬ê°„ì„ ë§Œë“¤ì–´ì¤Œ(ìë§‰ì€ ì´˜ì´˜í•œ dense ë²„ì „ìœ¼ë¡œ ë³„ë„ í‘œì‹œ).
    """
    if clip_count <= 0 or not segments:
        return segments
    total_duration = segments[-1]['end']
    target = total_duration / clip_count
    coalesced, cur_start, acc = [], segments[0]['start'], 0.0
    for s in segments:
        acc += (s['end'] - s['start'])
        if acc >= target and len(coalesced) < clip_count - 1:
            coalesced.append({'start': cur_start, 'end': s['end'], 'text': ''})
            cur_start, acc = s['end'], 0.0
    if len(coalesced) < clip_count:
        coalesced.append({'start': cur_start, 'end': segments[-1]['end'], 'text': ''})
    return coalesced

def get_web_documents_from_query(query: str):
    try:
        urls = get_links(query, num=40)
        crawl_results = clean_html_parallel(urls)
        docs = []
        for result in crawl_results:
            if result['success']:
                clean_text = filter_noise(result['text'])
                if len(clean_text.strip()) >= 100:
                    doc = Document(
                        page_content=clean_text.strip(),
                        metadata={"source": result['url']}
                    )
                    docs.append(doc)
        return docs, None
    except Exception as e:
        return [], str(e)


def patch_ass_center(ass_path: str):
    """ASS ìë§‰ì˜ ëª¨ë“  Dialogueì— {\an5}ë¥¼ ë¶™ì—¬ í™”ë©´ ì •ì¤‘ì•™ ì •ë ¬."""
    try:
        with open(ass_path, "r", encoding="utf-8") as f:
            lines = f.readlines()
        out = []
        for ln in lines:
            if ln.startswith("Dialogue:"):
                parts = ln.split(",", 9)
                if len(parts) >= 10 and r"{\an" not in parts[9]:
                    parts[9] = r"{\an5}" + parts[9]
                    ln = ",".join(parts)
            out.append(ln)
        with open(ass_path, "w", encoding="utf-8") as f:
            f.writelines(out)
    except Exception as e:
        print(f"ASS ì¤‘ì•™ ì •ë ¬ íŒ¨ì¹˜ ì‹¤íŒ¨: {e}")

def _normalize_scene_query(raw: str) -> str:
    import re
    if not raw:
        return ""
    s = raw.strip()

    # í”„ë¦¬ì•°ë¸” ì œê±°
    s = re.sub(r'(?i)^(here are .*?:)\s*', '', s)
    s = re.sub(r'(?i)^(keywords?|í‚¤ì›Œë“œ)\s*:\s*', '', s)

    # ì¤„ë°”ê¿ˆ/ë”°ì˜´í‘œ ì œê±°
    s = s.replace("\n", " ").replace("\r", " ")
    s = re.sub(r'["â€œâ€â€˜â€™\'`]+', '', s)

    # âœ… í—ˆìš© ë¬¸ì ë²”ìœ„ ì™„í™”: ì˜ë¬¸ + í•œê¸€ + ìˆ«ì + ê³µë°± + , - . / Â° %
    s = re.sub(r'[^A-Za-z\uAC00-\uD7A30-9 ,\-./Â°%]+', ' ', s)

    # âœ… ì²œë‹¨ìœ„Â·ì†Œìˆ˜ì  ì£¼ë³€ ê³µë°± ì •ë¦¬
    s = re.sub(r'\s*,\s*', ',', s)
    s = re.sub(r'\s*\.\s*', '.', s)

    # ê³µë°± ì •ë¦¬
    s = re.sub(r'\s{2,}', ' ', s).strip(' ,').strip()

    # ì‰¼í‘œë¡œ ìª¼ê°œ ìµœëŒ€ 3ì¡°ê°
    parts = [p.strip() for p in s.split(',') if p.strip()]
    if parts:
        s = ', '.join(parts[:3])

    # ë„ˆë¬´ ê¸¸ë©´ ì»·
    if len(s) > 90:
        s = s[:90].rstrip(' ,')

    return s

def _save_unique_image(src_path_or_url: str, idx: int) -> str:
    """
    ì´ë¯¸ì§€ê°€ ê°™ì€ íŒŒì¼ëª…ìœ¼ë¡œ ë®ì–´ì“°ê¸° ë˜ëŠ” ë¬¸ì œë¥¼ ë§‰ê¸° ìœ„í•´
    ë¬¸ì¥ ì¸ë±ìŠ¤ë³„ë¡œ ê³ ìœ  íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥/ë³µì‚¬í•©ë‹ˆë‹¤.
    - ë¡œì»¬ ê²½ë¡œë©´ copy
    - URLì´ë©´ ë‹¤ìš´ë¡œë“œ
    """
    import os, shutil, mimetypes
    import requests

    os.makedirs("assets/scene_images", exist_ok=True)

    def _guess_ext(p: str) -> str:
        # í™•ì¥ì ì¶”ì • (ì—†ìœ¼ë©´ .jpg)
        base, ext = os.path.splitext(p)
        if ext and len(ext) <= 5:
            return ext
        # URL/í—¤ë”ì—ì„œ MIMEìœ¼ë¡œ ì¶”ì •
        if p.startswith("http"):
            try:
                head = requests.head(p, timeout=10)
                ctype = head.headers.get("Content-Type", "")
                ext = mimetypes.guess_extension(ctype.split(";")[0].strip()) or ".jpg"
                return ext
            except Exception:
                return ".jpg"
        return ".jpg"

    ext = _guess_ext(src_path_or_url)
    dst = os.path.join("assets/scene_images", f"img_sent_{idx:02d}{ext}")

    try:
        if src_path_or_url.startswith("http"):
            r = requests.get(src_path_or_url, timeout=30)
            r.raise_for_status()
            with open(dst, "wb") as f:
                f.write(r.content)
        else:
            shutil.copyfile(src_path_or_url, dst)
    except Exception:
        # ì‹¤íŒ¨ ì‹œë¼ë„ ìµœì†Œí•œ ì›ë³¸ ê²½ë¡œë¥¼ ë°˜í™˜
        return src_path_or_url

    return dst

def get_scene_keywords_batch(sentence_units, persona_text: str):
    """
    ì—¬ëŸ¬ ë¬¸ì¥ì„ í•œ ë²ˆì— LLMì— ë³´ë‚´ì„œ, ë¬¸ì¥ ìˆ˜ë§Œí¼ í‚¤ì›Œë“œ ë¼ì¸ìœ¼ë¡œ ë°›ì•„ì˜µë‹ˆë‹¤.
    ì¶œë ¥ í˜•ì‹(ì¤‘ìš”): ië²ˆì§¸ ë¬¸ì¥ì€ 'i. keyword' í•œ ì¤„
    """
    scene_chain = get_default_chain(system_prompt="ë‹¹ì‹ ì€ ìˆí¼ ë¹„ì£¼ì–¼ ì¥ë©´ í‚¤ì›Œë“œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")

    numbered = "\n".join(f"{i+1}. {s}" for i, s in enumerate(sentence_units))
    prompt = f"""ë„ˆëŠ” ìˆí¼ ë¹„ë””ì˜¤/ì´ë¯¸ì§€ì˜ 'ì¥ë©´ ê²€ìƒ‰ í‚¤ì›Œë“œ'ë¥¼ ë§Œë“œëŠ” ë„ìš°ë¯¸ë‹¤.

[í˜ë¥´ì†Œë‚˜]
{persona_text}

[ë¬¸ì¥ë“¤]
{numbered}

[ìš”êµ¬]
- ê° ë¬¸ì¥ì— ëŒ€í•´ 1ì¤„ì˜ í‚¤ì›Œë“œë§Œ ìƒì„±
- ië²ˆì§¸ ì¤„ì€ 'i. one short phrase' í˜•ì‹
- ê° í‚¤ì›Œë“œëŠ” 3~6ë‹¨ì–´ì˜ ì˜ì–´ êµ¬ë¬¸, ë°˜ë“œì‹œ 1ê°œë§Œ
- ë°˜ë“œì‹œ í‚¤ì›Œë“œë§Œ, ë¼ë²¨/ì„¤ëª…/ë”°ì˜´í‘œ/ì¤„ë°”ê¿ˆ ì¶”ê°€ ê¸ˆì§€
- ê°™ì€(í˜¹ì€ ê±°ì˜ ê°™ì€) í‚¤ì›Œë“œ/êµ¬ë¥¼ ì—¬ëŸ¬ ì¤„ì— ë°˜ë³µ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ. ìœ ì‚¬ ê°œë…ì´ë©´ ìŠ¤íƒ€ì¼Â·ì‹œê°„ëŒ€Â·ë¡œì¼€ì´ì…˜ì„ ë°”ê¿” ë³€ì£¼í•  ê²ƒ.

ì‘ë‹µ:
"""

    raw = scene_chain.invoke({"question": prompt, "chat_history": []}).strip()
    lines = [ln.strip() for ln in raw.splitlines() if ln.strip()]

    # ë¬¸ì¥ ìˆ˜ë§Œí¼ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
    out = [""] * len(sentence_units)
    for ln in lines:
        m = re.match(r"^\s*(\d+)\.\s*(.+)$", ln)
        if not m:
            continue
        idx = int(m.group(1)) - 1
        if 0 <= idx < len(out):
            out[idx] = _normalize_scene_query(m.group(2))

    # ë¹„ì–´ ìˆëŠ” ê±´ ë¬¸ì¥ ì›ë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ì„œ í´ë°±
    for i, val in enumerate(out):
        if not val:
            try:
                t = GoogleTranslator(source='auto', target='en').translate(sentence_units[i])
            except Exception:
                t = sentence_units[i]
            out[i] = _normalize_scene_query(t)

    return out

# ---------- ì•± ê¸°ë³¸ ----------
st.set_page_config(page_title="Perfacto AI", page_icon="ğŸ¤–")
st.title("PerfactoAI")
st.markdown("Make your own vids automatically")


# ---------- ì„¸ì…˜ ----------
def _lock_title():
    st.session_state.title_locked = True


def _use_auto_title():
    st.session_state.title_locked = False
    auto = st.session_state.get("auto_video_title", "")
    if auto:
        st.session_state.video_title = auto


def _init_session():
    defaults = dict(
        messages=[],
        retriever=None,
        system_prompt="ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
        last_user_query="",
        video_title="",
        auto_video_title="",
        title_locked=False,
        edited_script_content="",
        selected_tts_provider="ElevenLabs",
        selected_tts_template="educational",
        selected_polly_voice_key="korean_female1",
        selected_subtitle_template="educational",
        bgm_path=None,
        include_voice=True,
        generated_topics=[],
        selected_generated_topic="",
        audio_path=None,
        last_rag_sources=[],
        persona_rag_flags={},
        persona_rag_retrievers={},
        upload_clicked=False,
        youtube_link="",
        video_binary_data=None,
        final_video_path=""
    )
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


_init_session()


# ---------- ì‚¬ì´ë“œë°” ----------
with st.sidebar:
    st.header("âš™ï¸ AI í˜ë¥´ì†Œë‚˜ ë° RAG ì„¤ì •")
    if "persona_blocks" not in st.session_state:
        st.session_state.persona_blocks = []

    delete_idx = None

    if st.button("â• í˜ë¥´ì†Œë‚˜ ì¶”ê°€"):
        st.session_state.persona_blocks.append({
            "name": "ìƒˆ í˜ë¥´ì†Œë‚˜",
            "text": "",
            "use_prev_idx": [],
            "result": ""
        })

    for i, block in enumerate(st.session_state.persona_blocks):
        st.markdown(f"---\n### í˜ë¥´ì†Œë‚˜ #{i+1} - `{block['name']}`")

        st.session_state.persona_blocks[i]["name"] = st.text_input(
            "í˜ë¥´ì†Œë‚˜ ì—­í•  ì´ë¦„", value=block["name"], key=f"name_{i}"
        )

        persona_options = [("persona", idx) for idx in range(len(st.session_state.persona_blocks)) if idx != i]
        prev_idxs = st.multiselect(
            "ì´ì „ í˜ë¥´ì†Œë‚˜ ì‘ë‹µ ì´ì–´ë°›ê¸°",
            options=persona_options,
            default=block.get("use_prev_idx", []),
            key=f"use_prev_idx_{i}",
            format_func=lambda x: f"{x[1]+1} - {st.session_state.persona_blocks[x[1]]['name']}"
        )
        st.session_state.persona_blocks[i]["use_prev_idx"] = prev_idxs

        st.session_state.persona_blocks[i]["text"] = st.text_area(
            "ì§€ì‹œ ë¬¸ì¥", value=block["text"], key=f"text_{i}"
        )

        rag_source = st.radio(
            "ğŸ“¡ ì‚¬ìš©í•  RAG ìœ í˜•:",
            options=["ì›¹ ê¸°ë°˜ RAG", "ìœ íŠœë¸Œ ìë§‰ ê¸°ë°˜ RAG"],
            index=None,
            key=f"rag_source_{i}"
        )

        youtube_channel_input = None
        if rag_source == "ìœ íŠœë¸Œ ìë§‰ ê¸°ë°˜ RAG":
            youtube_channel_input = st.text_input(
                "ìœ íŠœë¸Œ ì±„ë„ í•¸ë“¤ ë˜ëŠ” URL ì…ë ¥:",
                value="@ì—­ì‚¬ì´ì•¼ê¸°",
                key=f"youtube_channel_input_{i}"
            )

        if st.button(f"ğŸ§  í˜ë¥´ì†Œë‚˜ ì‹¤í–‰", key=f"run_{i}"):
            prev_blocks = []
            for ptype, pidx in st.session_state.persona_blocks[i].get("use_prev_idx", []):
                if ptype == "persona" and pidx != i:
                    prev_blocks.append(f"[í˜ë¥´ì†Œë‚˜ #{pidx+1}]\n{st.session_state.persona_blocks[pidx]['result']}")
            final_prompt = ("\n\n".join(prev_blocks) + "\n\nì§€ì‹œ:\n" + block["text"]) if prev_blocks else block["text"]

            retriever = None
            if rag_source == "ì›¹ ê¸°ë°˜ RAG":
                docs, error = get_web_documents_from_query(block["text"])
                if not error and docs:
                    retriever = get_retriever_from_source("docs", docs)
                    st.success(f"ğŸ“„ ì›¹ ë¬¸ì„œ {len(docs)}ê±´ ì ìš© ì™„ë£Œ")
                    with st.expander("ğŸ”— ì ìš©ëœ ì›¹ ë¬¸ì„œ ì¶œì²˜ ë³´ê¸°"):
                        for idx, doc in enumerate(docs, start=1):
                            url = doc.metadata.get("source", "ì¶œì²˜ ì—†ìŒ")
                            if url.startswith("http"):
                                st.markdown(f"- [ë¬¸ì„œ {idx}]({url})")
                            else:
                                st.markdown(f"- ë¬¸ì„œ {idx}: {url}")
                else:
                    st.warning(f"ì›¹ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: {error or 'ë¬¸ì„œ ì—†ìŒ'}")
            elif rag_source == "ìœ íŠœë¸Œ ìë§‰ ê¸°ë°˜ RAG":
                if youtube_channel_input and youtube_channel_input.strip():
                    subtitle_docs = load_best_subtitles_documents(youtube_channel_input.strip())
                    if subtitle_docs:
                        retriever = get_retriever_from_source("docs", subtitle_docs)
                        st.success(f"ğŸ¬ ìœ íŠœë¸Œ ìë§‰ {len(subtitle_docs)}ê±´ ì ìš© ì™„ë£Œ")
                    else:
                        st.warning("ìœ íŠœë¸Œ ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ìœ íŠœë¸Œ ì±„ë„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

            if retriever:
                st.session_state.persona_rag_flags[i] = True
                st.session_state.persona_rag_retrievers[i] = retriever
                rag_chain = get_conversational_rag_chain(retriever, st.session_state.system_prompt)
                rag_response = rag_chain.invoke({"input": final_prompt})
                content = rag_response.get("answer", rag_response.get("result", rag_response.get("content", "")))
                source_docs = rag_response.get("source_documents", [])
                sources = []
                for doc in source_docs:
                    snippet = doc.page_content.strip()
                    if len(snippet) > 300:
                        snippet = snippet[:300] + "..."
                    sources.append({"content": snippet, "source": doc.metadata.get("source", "ì¶œì²˜ ì—†ìŒ")})
                st.session_state.messages.append(AIMessage(content=content, additional_kwargs={"sources": sources}))
                st.session_state.persona_blocks[i]["result"] = content
            else:
                st.session_state.persona_rag_flags[i] = False
                result_text = generate_response_from_persona(final_prompt)
                st.session_state.messages.append(AIMessage(content=result_text))
                st.session_state.persona_blocks[i]["result"] = result_text

        if st.button(f"ğŸ—‘ï¸ í˜ë¥´ì†Œë‚˜ ì‚­ì œ", key=f"delete_{i}"):
            delete_idx = i

    if delete_idx is not None:
        del st.session_state.persona_blocks[delete_idx]
        st.rerun()

    st.markdown("---")
    with st.expander("ì˜ìƒ ì œì‘ ì„¤ì •", expanded=True):
        # ì˜ìƒ ìŠ¤íƒ€ì¼
        st.session_state.video_style = st.selectbox(
            "ì˜ìƒ ìŠ¤íƒ€ì¼ ì„ íƒ",
            ["ê¸°ë³¸ ì´ë¯¸ì§€+íƒ€ì´í‹€", "ê°ì„± í…ìŠ¤íŠ¸ ì˜ìƒ", VIDEO_TEMPLATE],
            index=0
        )
        is_emotional = (st.session_state.video_style == "ê°ì„± í…ìŠ¤íŠ¸ ì˜ìƒ")
        is_video_template = (st.session_state.video_style == VIDEO_TEMPLATE)

        st.subheader("ğŸ“œ ì‚¬ìš©í•  ìŠ¤í¬ë¦½íŠ¸ ì„ íƒ")
        available_personas_with_results = [
            (i, block["name"]) for i, block in enumerate(st.session_state.persona_blocks) if block.get("result", "").strip()
        ]

        if available_personas_with_results:
            selected_script_persona_idx = st.selectbox(
                "ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‚¬ìš©í•  í˜ë¥´ì†Œë‚˜ ì„ íƒ:",
                options=available_personas_with_results,
                format_func=lambda x: f"{x[0]+1} - {x[1]}",
                key="selected_script_persona_for_video",
                index=0
            )
            selected_idx = selected_script_persona_idx[0]
            selected_script = st.session_state.persona_blocks[selected_idx]["result"]
            st.session_state.selected_script_persona_index = selected_idx
            
            st.session_state.edited_script_content = st.text_area(
                "ğŸ¬ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© ìˆ˜ì •",
                value=selected_script,
                key="script_editor_editable"
            )

            if not is_video_template:
                with st.spinner("ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì˜ìƒ ì œëª©ì„ ì¶”ì¶œ ì¤‘..."):
                    title_prompt = f"""ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ì— ê¸°ë°˜í•´ ë§¤ë ¥ì ì´ê³  ì„íŒ©íŠ¸ ìˆëŠ” ì§§ì€ í•œêµ­ì–´ ì˜ìƒ ì œëª©ì„ ìƒì„±í•˜ì„¸ìš”. ì œëª©ë§Œ ì‘ë‹µí•˜ì„¸ìš”.

ìŠ¤í¬ë¦½íŠ¸:
{selected_script}

ì œëª©:"""
                    title_llm_chain = get_default_chain(system_prompt="ë‹¹ì‹ ì€ ìˆí¼ ì˜ìƒ ì œëª©ì„ ì§“ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")
                    title = title_llm_chain.invoke({"question": title_prompt, "chat_history": []}).strip()
                    st.session_state.auto_video_title = title
                    if not st.session_state.get("title_locked", False):
                        st.session_state.video_title = title
        else:
            st.warning("ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í˜ë¥´ì†Œë‚˜ ì‹¤í–‰ì„ í†µí•´ ê²°ê³¼ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.")

        # ì œëª© ì…ë ¥ì¹¸: VIDEO_TEMPLATEì—ì„œëŠ” ìˆ¨ê¹€
        if not is_video_template:
            st.session_state.video_title = st.text_input(
                "ì˜ìƒ ì œëª© (ì˜ìƒ ìœ„ì— í‘œì‹œë  ì œëª©)",
                value=st.session_state.video_title,
                key="video_title_input_final",
                on_change=_lock_title
            )
        else:
            st.session_state.video_title = ""  # ì œëª© ì‚¬ìš© ì•ˆ í•¨

        if is_emotional:
            st.info("ê°ì„± í…ìŠ¤íŠ¸ ì˜ìƒì€ **ì´ë¯¸ì§€/ìŒì„± ì—†ì´** í…ìŠ¤íŠ¸ + (ì„ íƒ) BGMìœ¼ë¡œë§Œ ì œì‘ë©ë‹ˆë‹¤.")
            st.session_state.include_voice = False
        else:
            st.session_state.include_voice = st.checkbox("ì˜ìƒì— AI ëª©ì†Œë¦¬ í¬í•¨", value=st.session_state.include_voice)
            if st.session_state.include_voice:
                st.session_state.selected_tts_provider = st.radio(
                    "ìŒì„± ì„œë¹„ìŠ¤ ê³µê¸‰ì ì„ íƒ:",
                    ("ElevenLabs", "Amazon Polly"),
                    index=0 if st.session_state.selected_tts_provider == "ElevenLabs" else 1,
                    key="tts_provider_select"
                )
                if st.session_state.selected_tts_provider == "ElevenLabs":
                    elevenlabs_template_names = list(TTS_ELEVENLABS_TEMPLATES.keys())
                    st.session_state.selected_tts_template = st.selectbox(
                        "ElevenLabs ìŒì„± í…œí”Œë¦¿ ì„ íƒ:",
                        options=elevenlabs_template_names,
                        index=elevenlabs_template_names.index(st.session_state.selected_tts_template)
                        if st.session_state.selected_tts_template in elevenlabs_template_names else 0,
                        key="elevenlabs_template_select"
                    )
                else:
                    polly_voice_keys = list(TTS_POLLY_VOICES.keys())
                    st.session_state.selected_polly_voice_key = st.selectbox(
                        "Amazon Polly ìŒì„± ì„ íƒ:",
                        options=polly_voice_keys,
                        index=polly_voice_keys.index(st.session_state.selected_polly_voice_key)
                        if st.session_state.selected_polly_voice_key in polly_voice_keys else 0,
                        key="polly_voice_select"
                    )

        st.session_state.selected_tts_lang = st.radio(
            "ğŸ™ï¸ ìŒì„± ì–¸ì–´ ì„ íƒ:",
            options=["ko", "en"],
            index=0,  # ê¸°ë³¸ í•œêµ­ì–´
            key="tts_lang_select"
        )
        
        if not is_emotional:
            st.session_state.selected_subtitle_template = st.selectbox(
                "ìë§‰ í…œí”Œë¦¿ ì„ íƒ",
                options=list(SUBTITLE_TEMPLATES.keys()),
                index=list(SUBTITLE_TEMPLATES.keys()).index(st.session_state.selected_subtitle_template)
            )

        uploaded_bgm_file = st.file_uploader("BGM íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ ì‚¬í•­, .mp3, .wav)", type=["mp3", "wav"])
        if uploaded_bgm_file:
            temp_bgm_path = os.path.join("assets", uploaded_bgm_file.name)
            os.makedirs("assets", exist_ok=True)
            with open(temp_bgm_path, "wb") as f:
                f.write(uploaded_bgm_file.read())
            st.session_state.bgm_path = temp_bgm_path
            st.success(f"ë°°ê²½ ìŒì•… '{uploaded_bgm_file.name}' ì—…ë¡œë“œ ì™„ë£Œ!")

        st.subheader("ì˜ìƒ ì œì‘")
        if st.button("ì˜ìƒ ë§Œë“¤ê¸°"):
            # ì´ˆê¸°í™”
            st.session_state.video_binary_data = None
            st.session_state.final_video_path = ""
            st.session_state.youtube_link = ""
            st.session_state.upload_clicked = False
            # main.py â€” "ì˜ìƒ ë§Œë“¤ê¸°" ë²„íŠ¼ ì•ˆ, ë¬¸ì¥ë³„ ì˜ìƒ ê²€ìƒ‰ ì§ì „ì— ì¶”ê°€
            if "seen_video_ids" not in st.session_state:
                st.session_state.seen_video_ids = set()
            if "query_page_cursor" not in st.session_state:
                st.session_state.query_page_cursor = {}  # {query: next_page_int}
            if "seen_photo_ids" not in st.session_state:
                st.session_state.seen_photo_ids = set()
            if "query_page_cursor_img" not in st.session_state:
                st.session_state.query_page_cursor_img = {}  # {query: next_page_int}
                
            final_script_for_video = st.session_state.edited_script_content
            final_title_for_video = st.session_state.video_title  # VIDEO_TEMPLATEì´ë©´ ë¹ˆ ë¬¸ìì—´ì´ì–´ë„ ë¨

            if not final_script_for_video.strip():
                st.error("ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                st.stop()

            # ì œëª©ì€ VIDEO_TEMPLATEì¼ ë•Œ í•„ìˆ˜ ì•„ë‹˜
            if (not is_video_template) and (not final_title_for_video.strip()):
                st.error("ì˜ìƒ ì œëª©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                st.stop()

            with st.spinner("âœ¨ ì˜ìƒ ì œì‘ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    media_query_final = ""
                    audio_path = None
                    segments = []
                    ass_path = None

                    # --- ìŒì„± í¬í•¨/ë¯¸í¬í•¨ ë¶„ê¸° ---
                    if not is_emotional and st.session_state.include_voice:
                        # (ì¤‘ìš”) ì´ì¤‘ ìŒì„± ë°©ì§€: ë³„ë„ì˜ ë‹¨ë°œ TTS ìƒì„± ì—†ì´
                        # generate_subtitle_from_script í•œ ë²ˆìœ¼ë¡œ ë¼ì¸ë³„ TTSâ†’ë³‘í•©ê¹Œì§€ ìˆ˜í–‰.
                        audio_output_dir = "assets"
                        os.makedirs(audio_output_dir, exist_ok=True)
                        audio_path = os.path.join(audio_output_dir, "generated_audio.mp3")

                        st.write("ğŸ—£ï¸ ë¼ì¸ë³„ TTS ìƒì„±/ë³‘í•© ë° ì„¸ê·¸ë¨¼íŠ¸ ì‚°ì¶œ ì¤‘...")
                        provider = "elevenlabs" if st.session_state.selected_tts_provider == "ElevenLabs" else "polly"
                        tmpl = st.session_state.selected_tts_template if provider == "elevenlabs" else st.session_state.selected_polly_voice_key
                        
                        segments, audio_clips, ass_path = generate_subtitle_from_script(
                            script_text=final_script_for_video,
                            ass_path=os.path.join("assets", "generated_subtitle.ass"),
                            full_audio_file_path=audio_path,
                            provider=provider,
                            template=tmpl,
                            polly_voice_key=st.session_state.selected_polly_voice_key,  # âœ… ì‹¤ì œ ì„ íƒ ë³´ì´ìŠ¤ ë°˜ì˜
                            subtitle_lang="ko",
                            translate_only_if_english=False,
                            tts_lang=st.session_state.selected_tts_lang,
                            split_mode="new_line",
                            strip_trailing_punct_last=False
                        )
                        
                        try:
                            with AudioFileClip(audio_path) as aud:
                                aud_dur = float(aud.duration or 0.0)
                            if segments and aud_dur > 0:
                                # ì•½ê°„ì˜ ì—¬ìœ (20ms) ì¤˜ì„œ -shortest íŠ¸ë¦¼ ë°©ì§€
                                if aud_dur + 0.02 > segments[-1]["end"]:
                                    segments[-1]["end"] = aud_dur + 0.02
                        except Exception as e:
                            print("Audio length check failed:", e)
                        
                        # âœ… ìƒì„± ì§í›„ 'ì§„ì§œë¡œ' ë§Œë“¤ì–´ì¡ŒëŠ”ì§€ ê°•ì œ ê²€ì¦
                        if not segments:
                            st.error("TTS ìƒì„± ì‹¤íŒ¨: ì„¸ê·¸ë¨¼íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. (ë¼ì¸ë³„ ì‹¤íŒ¨ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”)")
                            st.stop()

                        try:
                            sz = os.path.getsize(audio_path)
                        except Exception:
                            sz = 0
                        if sz < 5_000:  # 5KB ë¯¸ë§Œì´ë©´ ì‚¬ì‹¤ìƒ ì‹¤íŒ¨ë¡œ ê°„ì£¼
                            st.error(f"TTS ìƒì„± ì‹¤íŒ¨: ì˜¤ë””ì˜¤ íŒŒì¼ ìš©ëŸ‰ì´ ë¹„ì •ìƒì ì…ë‹ˆë‹¤ ({sz} bytes).")
                            st.stop()

                        # === ê¸°ì¡´ dense ìƒì„± ë¶€ë¶„ êµì²´(ìƒì„± ê·¸ëŒ€ë¡œ) ===
                        dense_events = []

                        def _densify_for_fast_tempo(events, words_per_piece=2):
                            # ë‹¨ì–´ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ëª©í‘œ ì´ë²¤íŠ¸ ê°œìˆ˜ ì‚°ì • â†’ ë” ì´˜ì´˜í•˜ê²Œ ë¶„í• 
                            import math
                            total_tokens = sum(len(_tokenize_words_for_kr_en(e.get("text",""))) for e in events)
                            if total_tokens == 0: 
                                return events
                            target = max(len(events), math.ceil(total_tokens / max(1, int(words_per_piece))))
                            return densify_subtitles_by_words(events, target)

                        for seg in segments:  # seg = {"start","end","text","ssml"(optional)}
                            if seg.get("ssml"):
                                ev = _build_dense_from_ssml(seg["ssml"], seg["start"], seg["end"], fps=30.0)
                                # ğŸ”¥ SSMLë„ ë¹ ë¥¸ í…œí¬ë¡œ ë” ì´˜ì´˜íˆ ë¶„í• 
                                ev = _densify_for_fast_tempo(ev, words_per_piece=2)
                                dense_events += ev
                            else:
                                dense_events += auto_densify_for_subs(
                                    [seg], tempo="fast", words_per_piece=2,
                                    min_tail_words=2, chunk_strategy=None,
                                    marks_voice_key=st.session_state.selected_polly_voice_key,
                                    max_chars_per_piece=14, min_piece_dur=0.50
                                )

                        # === â‘  ê²½ê³„ ë³´ê°• ===
                        dense_events = harden_ko_sentence_boundaries(dense_events)

                        # === â‘¡ í…ìŠ¤íŠ¸ ë³´í˜¸/ì •ë¦¬(ì¤„ ê°•ì œ ì—†ì´ "ë³´í˜¸" ìœ„ì£¼) ===
                        def drop_or_fix_empty_text(events):
                            out = []
                            for e in events:
                                t = (e.get("text") or "").strip()
                                if not t.replace(NBSP, ""):
                                    t = NBSP
                                out.append({**e, "text": t})
                            return out

                        def ensure_min_frames(events, fps=30.0, min_frames=2):
                            tick = 1.0 / float(fps)
                            min_d = min_frames * tick
                            out = []
                            for i, e in enumerate(events):
                                s, ed = float(e["start"]), float(e["end"])
                                if ed - s < min_d:
                                    ed = s + min_d
                                # ë‹¤ìŒ cueì™€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ë§ˆì§€ë§‰ì— í•œë²ˆ ë” clamp
                                out.append({**e, "start": round(s, 3), "end": round(ed, 3)})
                            # ì¸ì ‘ ê²¹ì¹¨ ë°©ì§€
                            for i in range(len(out) - 1):
                                if out[i]["end"] > out[i+1]["start"]:
                                    out[i]["end"] = max(out[i]["start"], out[i+1]["start"] - 0.001)
                            return out

                        def prepare_text_for_ass(text: str, one_line_threshold=12, biline_target=14):
                            """
                            - '1ì¤„ì´ë©´ ë¬´ì¡°ê±´ 1ì¤„' ì›ì¹™ì„ ë°˜ì˜í•˜ë˜, ìƒìœ„ generate_ass_subtitleê°€ ìµœì¢… íŒë‹¨.
                            - ì—¬ê¸°ì„œëŠ” ê°€ë²¼ìš´ ë³´í˜¸ë§Œ: ìˆ«ì+ë‹¨ìœ„, ìˆ˜ëŸ‰ ì–´êµ¬ NBSP, ë§ê¼¬ë¦¬ ë³´í˜¸.
                            """
                            t = (text or "").strip()
                            if not t:
                                return NBSP
                            # ë³´í˜¸(ìˆ«ì+ë‹¨ìœ„/ìˆ˜ëŸ‰ ë“±) â€” ê¸°ì¡´ bind_compoundsê°€ ìˆë‹¤ë©´ í™œìš©
                            try:
                                t = bind_compounds(t)
                            except Exception:
                                pass
                            # ë§ê¼¬ë¦¬ ë³´í˜¸(ì˜µì…˜ í•¨ìˆ˜ê°€ ìˆë‹¤ë©´)
                            try:
                                from re import compile
                                def _protect_short_tail_nbsp_local(s: str) -> str:
                                    NB = "\u00A0"
                                    TAILS = [r"ê°™ì£ \?", r"ê·¸ë ‡ì£ \?", r"ê·¸ì£ \?", r"ê·¸ì£ ",
                                            r"ì´ì£ \?", r"ì´ì£ ", r"ì£ \?", r"ì£ ",
                                            r"ì…ë‹ˆë‹¤", r"ì˜ˆìš”", r"ì´ì—ìš”", r"ì´ë‹¤", r"ë‹¤$"]
                                    pat = compile(r"\s+(?=(" + "|".join(TAILS) + r"))")
                                    return pat.sub(NB, s)
                                t = _protect_short_tail_nbsp_local(t)
                            except Exception:
                                pass
                            # 1ì¤„ ì„ í˜¸ â†’ ê¸¸ì´ê°€ ì•„ì£¼ ì§§ìœ¼ë©´ ì•„ì˜ˆ 1ì¤„ ê³ ì •
                            if len(t) <= one_line_threshold:
                                return t
                            # 2ì¤„ í•„ìš” íŒë‹¨ì€ generate_ass_subtitleì—ì„œ ìµœì¢… ì²˜ë¦¬(\N ì‚½ì…)
                            return t

                        dense_events = [{**e, "text": prepare_text_for_ass(e["text"], one_line_threshold=12, biline_target=14)} for e in dense_events]
                        dense_events = dedupe_adjacent_texts(dense_events)
                        dense_events = drop_or_fix_empty_text(dense_events)

                        # === â‘¢ íƒ€ì´ë° ì•ˆì •í™” ===
                        dense_events = clamp_no_overlap(dense_events, margin=0.02)
                        dense_events = enforce_min_duration_non_merging(dense_events, min_dur=0.50, margin=0.02)
                        dense_events = quantize_events(dense_events, fps=30.0)
                        dense_events = ensure_min_frames(dense_events, fps=30.0, min_frames=2)

                        # â‘¤ ASS ìƒì„±
                        generate_ass_subtitle(
                            segments=dense_events,
                            ass_path=ass_path,
                            template_name=st.session_state.selected_subtitle_template,
                            strip_trailing_punct_last=True,
                            max_chars_per_line=14,
                            max_lines=2
                        )
                        segments_for_video = dense_events

                        try:
                            if audio_clips is not None:
                                audio_clips.close()
                        except:
                            pass

                        if is_video_template:
                            patch_ass_center(ass_path)
                        st.success(f"ìŒì„±/ìë§‰ ìƒì„± ì™„ë£Œ: {audio_path}, {ass_path}")
                        st.session_state.audio_path = audio_path

                    else:
                        # ìŒì„± ì—†ì´ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±(í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜)
                        st.write("ğŸ”¤ ìŒì„± ì—†ì´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±")
                        sentences = re.split(r'(?<=[.?!])\s*', final_script_for_video.strip())
                        sentences = [s.strip() for s in sentences if s.strip()]
                        if not sentences:
                            sentences = [final_script_for_video.strip()]

                        words_per_minute = 150
                        total_script_words = len(final_script_for_video.split())
                        total_estimated_duration_seconds = max(5, (total_script_words / words_per_minute) * 60)

                        current_time = 0.0
                        total_chars = sum(len(s) for s in sentences)
                        for sentence_text in sentences:
                            min_segment_duration = 1.5
                            if total_chars > 0:
                                proportion = len(sentence_text) / total_chars
                                segment_duration = total_estimated_duration_seconds * proportion
                            else:
                                segment_duration = total_estimated_duration_seconds / len(sentences)
                            segment_duration = max(min_segment_duration, segment_duration)
                            segments.append({"start": current_time, "end": current_time + segment_duration, "text": sentence_text})
                            current_time += segment_duration
                        if segments:
                            segments[-1]["end"] = current_time

                        if not is_emotional:
                            ass_path = os.path.join("assets", "generated_subtitle.ass")
                            st.write("ğŸ“ ìë§‰ íŒŒì¼ ìƒì„± ì¤‘...")
                            generate_ass_subtitle(
                                segments=segments,
                                ass_path=ass_path,
                                template_name=st.session_state.selected_subtitle_template
                            )
                            if is_video_template:
                                patch_ass_center(ass_path)
                            st.success(f"ìë§‰ íŒŒì¼ ìƒì„± ì™„ë£Œ: {ass_path}")
                            # ğŸ”§ ì˜ìƒ í•©ì„±ì—ì„œ ì°¸ì¡°í•  ìµœì¢… ì„¸ê·¸ë¨¼íŠ¸ ì…‹ì—…
                            segments_for_video = [{**e, "text": prepare_text_for_ass(e["text"], one_line_threshold=12, biline_target=14)} for e in segments]
                            segments_for_video = dedupe_adjacent_texts(segments_for_video)
                            segments_for_video = drop_or_fix_empty_text(segments_for_video)
                            segments_for_video = clamp_no_overlap(segments_for_video, margin=0.02)
                            segments_for_video = enforce_min_duration_non_merging(segments_for_video, min_dur=0.50, margin=0.02)
                            segments_for_video = quantize_events(segments_for_video, fps=30.0)
                            segments_for_video = ensure_min_frames(segments_for_video, fps=30.0, min_frames=2)

                    # --- ë¯¸ë””ì–´(ì´ë¯¸ì§€ or ì˜ìƒ) ìˆ˜ì§‘ ---
                    image_paths, video_paths = [], []
                    if st.session_state.video_style != "ê°ì„± í…ìŠ¤íŠ¸ ì˜ìƒ":
                        if is_video_template:
                            # âœ… ë¬¸ì¥ ë‹¨ìœ„(segments)ë¡œ ë¬¸ì¥ë³„ í‚¤ì›Œë“œ ìƒì„± â†’ ì˜ìƒ 1ê°œì”© ë§¤ì¹­
                            st.write("ğŸ¯ ë¬¸ì¥ë³„ë¡œ í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ í‚¤ì›Œë“œë¥¼ ë§Œë“¤ì–´ ê°œë³„ ì˜ìƒ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

                            # 1) ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
                            sentence_units = [s['text'] for s in segments]

                            # 2) í˜ë¥´ì†Œë‚˜ ì§€ì‹œë¬¸
                            persona_text = ""
                            try:
                                pidx = st.session_state.get("selected_script_persona_index", None)
                                if pidx is not None:
                                    persona_text = st.session_state.persona_blocks[pidx]["text"]
                            except Exception:
                                persona_text = ""

                            # 3) âœ… ë¬¸ì¥ë³„ í‚¤ì›Œë“œë¥¼ í•œ ë²ˆì— ë°›ê¸° (ë°°ì¹˜)
                            per_sentence_queries = get_scene_keywords_batch(sentence_units, persona_text)
                            for i, q in enumerate(per_sentence_queries, start=1):
                                st.write(f"ğŸ§© ë¬¸ì¥ {i} í‚¤ì›Œë“œ(ì •ê·œí™”): {q}")

                            # 4) ë¬¸ì¥ë³„ë¡œ ì˜ìƒ 1ê°œì”© ê²€ìƒ‰
                            video_paths = []

                            def _try_search_once(q: str, clip_idx: int):
                                # í‚¤ì›Œë“œë³„ ë‹¤ìŒ í˜ì´ì§€ ì»¤ì„œ (ê¸°ë³¸ 1)
                                pg = st.session_state.query_page_cursor.get(q, 1)
                                paths, ids = generate_videos_for_topic(
                                    query=q,
                                    num_videos=1,
                                    start_index=clip_idx,           # íŒŒì¼ëª… ì¼ê´€ì„± ìœ ì§€
                                    orientation="portrait",
                                    page=pg,                        # âœ… ì´ í‚¤ì›Œë“œëŠ” ì—¬ê¸°ì„œë¶€í„°
                                    exclude_ids=st.session_state.seen_video_ids,  # âœ… ì´ë¯¸ ì“´ ê±´ ê±´ë„ˆë›°ê¸°
                                    return_ids=True
                                )
                                if paths:
                                    # ì„±ê³µ â†’ ë‹¤ìŒì— ê°™ì€ í‚¤ì›Œë“œ ì“°ë©´ ë‹¤ìŒ í˜ì´ì§€ë¶€í„°
                                    st.session_state.query_page_cursor[q] = pg + 1
                                    st.session_state.seen_video_ids.update(ids)
                                return paths

                            for clip_idx, q in enumerate(per_sentence_queries, start=1):
                                st.write(f"ğŸï¸ ë¬¸ì¥ {clip_idx} ê²€ìƒ‰: {q}")

                                got = _try_search_once(q, clip_idx)

                                # ì½¤ë§ˆë¡œ ë‚˜ë‰œ êµ¬ë¬¸ì´ë©´ ì¡°ê°ë³„ë¡œë„ ì¬ì‹œë„
                                if not got and ("," in q):
                                    for piece in [p.strip() for p in q.split(",") if p.strip()]:
                                        got = _try_search_once(piece, clip_idx)
                                        if got: break

                                # ê·¸ë˜ë„ ì—†ìœ¼ë©´ í‚¤ì›Œë“œ ì •ê·œí™” í›„ í•œ ë²ˆ ë”
                                if not got:
                                    fb = _normalize_scene_query(q)
                                    got = _try_search_once(fb, clip_idx)

                                if got:
                                    video_paths.extend(got)

                            # 5) ê¸¸ì´ ë³´ì •
                            if len(video_paths) < len(segments):
                                st.warning(f"ì˜ìƒì´ {len(video_paths)}ê°œë¿ì…ë‹ˆë‹¤. ì¼ë¶€ ë¬¸ì¥ì€ ë§ˆì§€ë§‰ í´ë¦½ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
                                if video_paths:
                                    video_paths += [video_paths[-1]] * (len(segments) - len(video_paths))

                        else:
                            # --- ì´ë¯¸ì§€ ìˆ˜ì§‘(ë¬¸ì¥ë‹¹ 1ì¥, ë¶€ì¡± ì‹œ ì¶”ê°€ íƒìƒ‰) ---
                            st.write("ğŸ–¼ï¸ ë¬¸ì¥ë³„ë¡œ í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ í‚¤ì›Œë“œë¥¼ ë§Œë“¤ì–´ ì´ë¯¸ì§€ 1ì¥ì”© ìƒì„±/ê²€ìƒ‰í•©ë‹ˆë‹¤.") 

                            persona_text = ""
                            try:
                                pidx = st.session_state.get("selected_script_persona_index", None)
                                if pidx is not None:
                                    persona_text = st.session_state.persona_blocks[pidx]["text"]
                            except Exception:
                                pass

                            image_paths = build_image_paths_for_dense_segments(segments_for_video, persona_text)


                    # --- í•©ì„± ---
                    video_output_dir = "assets"
                    os.makedirs(video_output_dir, exist_ok=True)
                    temp_video_path = os.path.join(video_output_dir, "temp_video.mp4")
                    final_video_path = os.path.join(video_output_dir, "final_video_with_subs.mp4")

                    st.write("ğŸ¬ ë¹„ë””ì˜¤ í•©ì„± ì¤‘...")
                    if is_emotional:
                        created_video_path = create_dark_text_video(
                            script_text=final_script_for_video,
                            title_text="",  # ê°ì„± í…ìŠ¤íŠ¸: í™”ë©´ ì œëª© ë¹„ì‚¬ìš©
                            audio_path=None,
                            bgm_path=st.session_state.bgm_path,
                            save_path=temp_video_path
                        )
                        final_video_with_subs_path = created_video_path
                    else:
                        if is_video_template:
                            created_video_path = create_video_from_videos(
                                video_paths=video_paths,
                                segments=segments_for_video,  # âœ… ë³‘í•©/ì¡°ì •ëœ êµ¬ê°„ ì‚¬ìš©
                                audio_path=st.session_state.audio_path if st.session_state.include_voice else None,
                                topic_title="",
                                include_topic_title=False,
                                bgm_path=st.session_state.bgm_path,
                                save_path=temp_video_path
                            )
                        else:
                            created_video_path = create_video_with_segments(
                                image_paths=image_paths,
                                segments=segments_for_video,
                                audio_path=st.session_state.audio_path if st.session_state.include_voice else None,
                                topic_title=st.session_state.video_title,
                                include_topic_title=True,
                                bgm_path=st.session_state.bgm_path,
                                save_path=temp_video_path
                            )

                        # ìë§‰ ì˜¤ë²„ë ˆì´
                        st.write("ğŸ“ ìë§‰ ì…íˆëŠ” ì¤‘...")
                        final_video_with_subs_path = add_subtitles_to_video(
                            input_video_path=created_video_path,
                            ass_path=ass_path,
                            output_path=final_video_path
                        )

                    st.success(f"âœ… ìµœì¢… ì˜ìƒ ìƒì„± ì™„ë£Œ: {final_video_with_subs_path}")
                    st.session_state["final_video_path"] = final_video_with_subs_path

                except Exception as e:
                    st.error(f"âŒ ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                    st.exception(e)

    st.divider()
    # ---------- ë‹¤ìš´ë¡œë“œ & ì—…ë¡œë“œ ----------
    with st.expander("ğŸ“¤ ë‹¤ìš´ë¡œë“œ ë° ì—…ë¡œë“œ", expanded=True):
        final_path = st.session_state.get("final_video_path", "")
        if final_path and os.path.exists(final_path):
            st.video(final_path)
            data_for_download = st.session_state.get("video_binary_data", None)
            if data_for_download is None:
                try:
                    with open(final_path, "rb") as f:
                        data_for_download = f.read()
                    st.session_state.video_binary_data = data_for_download
                except Exception as e:
                    st.error(f"ì˜ìƒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                    data_for_download = b""
            st.download_button(
                label="ğŸ¬ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                data=data_for_download,
                file_name="generated_multimodal_video.mp4",
                mime="video/mp4"
            )
            if not st.session_state.upload_clicked:
                if st.button("YouTubeì— ìë™ ì—…ë¡œë“œ"):
                    try:
                        youtube_link = upload_to_youtube(
                            final_path,
                            title=st.session_state.get("video_title") or "AI ìë™ ìƒì„± ì˜ìƒ"  # ê¸°ë³¸ê°’
                        )
                        st.session_state.upload_clicked = True
                        st.session_state.youtube_link = youtube_link
                        st.success("âœ… YouTube ì—…ë¡œë“œ ì™„ë£Œ!")
                        st.markdown(f"[ğŸ“º ì˜ìƒ ë³´ëŸ¬ê°€ê¸°]({youtube_link})")
                    except Exception as e:
                        st.error(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            else:
                st.success("âœ… YouTube ì—…ë¡œë“œ ì™„ë£Œë¨")
                st.markdown(f"[ğŸ“º ì˜ìƒ ë³´ëŸ¬ê°€ê¸°]({st.session_state.youtube_link})")
        else:
            st.info("ğŸ“Œ ë¨¼ì € 'ì˜ìƒ ë§Œë“¤ê¸°'ë¥¼ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")

    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()


# ---------- ë©”ì¸ ì±„íŒ… ----------
for message in st.session_state.messages:
    with st.chat_message(message.type):
        st.markdown(message.content)
        if message.type == "ai" and hasattr(message, "additional_kwargs") and "sources" in message.additional_kwargs and message.additional_kwargs["sources"]:
            st.subheader("ğŸ“š ì°¸ê³  ë¬¸ë‹¨ (RAG ê¸°ë°˜)")
            for idx, source_item in enumerate(message.additional_kwargs["sources"], start=1):
                content_display = source_item["content"]
                source_url_display = source_item.get("source", "N/A")
                if len(content_display) > 200:
                    content_display = content_display[:200] + "..."
                if source_url_display != 'N/A':
                    st.markdown(f"**ì¶œì²˜ {idx}:** [{source_url_display}]({source_url_display})\n> {content_display}")
                else:
                    st.markdown(f"**ì¶œì²˜ {idx}:**\n> {content_display}")

if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš” (ì˜ˆ: ìµœê·¼ AI ê¸°ìˆ  íŠ¸ë Œë“œ ì•Œë ¤ì¤˜)"):
    st.session_state.messages.append(HumanMessage(content=user_input))
    with st.chat_message("human"):
        st.markdown(user_input)
    st.session_state.last_user_query = user_input

    with st.chat_message("ai"):
        container = st.empty()
        ai_answer = ""
        sources_list = []

        if st.session_state.retriever:
            rag_chain = get_conversational_rag_chain(st.session_state.retriever, st.session_state.system_prompt)
            rag_response = rag_chain.invoke({"input": user_input})
            ai_answer = rag_response.get("answer", rag_response.get("result", rag_response.get("content", "")))
            source_docs = rag_response.get("source_documents", [])
            sources_list = []
            for doc in source_docs:
                sources_list.append({"content": doc.page_content[:200], "source": doc.metadata.get("source", "ì¶œì²˜ ì—†ìŒ")})
            container.markdown(ai_answer)
            st.session_state.messages.append(AIMessage(content=ai_answer, additional_kwargs={"sources": sources_list}))
        else:
            chain = get_default_chain(st.session_state.system_prompt)
            for token in chain.stream({"question": user_input, "chat_history": st.session_state.messages}):
                ai_answer += token
                container.markdown(ai_answer)

        if sources_list:
            st.write("### ğŸ“š ì°¸ê³  ë¬¸ë‹¨ (RAG ê¸°ë°˜)")
            for idx, source_item in enumerate(sources_list, start=1):
                content_display = source_item["content"]
                source_url_display = source_item.get("source", "N/A")
                if len(content_display) > 200:
                    content_display = content_display[:200] + "..."
                if source_url_display != 'N/A':
                    st.markdown(f"**ì¶œì²˜ {idx}:** [{source_url_display}]({source_url_display})\n> {content_display}")
                else:
                    st.markdown(f"**ì¶œì²˜ {idx}:**\n> {content_display}")

    # ì±„íŒ… ë‹µë³€ì„ ê³§ë°”ë¡œ ìŠ¤í¬ë¦½íŠ¸/ì£¼ì œë¡œ ë°˜ì˜
    st.session_state.edited_script_content = ai_answer
    if st.session_state.video_style != VIDEO_TEMPLATE:
        with st.spinner("ë‹µë³€ì—ì„œ ì˜ìƒ ì œëª©ì„ ìë™ ì¶”ì¶œ ì¤‘..."):
            title_extraction_prompt = f"""ë‹¹ì‹ ì€ TikTok, YouTube Shorts, Instagram Reelsìš© **ë§¤ë ¥ì ì´ê³  ë°”ì´ëŸ´ì„± ìˆëŠ” ìˆí¼ ë¹„ë””ì˜¤ ì œëª©**ì„ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ **ìµœëŒ€ 5ë‹¨ì–´ ì´ë‚´**ì˜ ê°•ë ¬í•œ í•œêµ­ì–´ ì œëª©ë§Œ ìƒì„±í•˜ì„¸ìš”.

ìŠ¤í¬ë¦½íŠ¸:
{ai_answer}

ì˜ìƒ ì œëª©:"""
            title_llm_chain = get_default_chain(
                system_prompt="ë‹¹ì‹ ì€ ìˆí¼ ë¹„ë””ì˜¤ìš© ë§¤ìš° ì§§ê³  ê°•ë ¬í•œ í•œêµ­ì–´ ì œëª©ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ AIì…ë‹ˆë‹¤. í•­ìƒ 5ë‹¨ì–´ ì´ë‚´."
            )
            extracted_title_for_ui = title_llm_chain.invoke({"question": title_extraction_prompt, "chat_history": []}).strip()
            if extracted_title_for_ui:
                extracted_title_for_ui = re.sub(r'[\U00010000-\U0010ffff]', '', extracted_title_for_ui).strip()
                st.session_state.auto_video_title = extracted_title_for_ui
                if not st.session_state.get("title_locked", False):
                    st.session_state.video_title = extracted_title_for_ui
            else:
                if not st.session_state.get("video_title"):
                    st.session_state.video_title = "ì œëª© ì—†ìŒ"
