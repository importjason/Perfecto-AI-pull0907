from moviepy import (
    ImageClip, AudioFileClip, concatenate_videoclips,
    CompositeVideoClip, TextClip, ColorClip, CompositeAudioClip
)
import os
import random
import subprocess
import numpy as np
from moviepy.audio.AudioClip import AudioArrayClip
import imageio_ffmpeg

def create_motion_clip(img_path, duration, width, height):
    base_clip_original_size = ImageClip(img_path)

    # ì´ë¯¸ì§€ ì´ˆê¸° ë¦¬ì‚¬ì´ì§• ì „ëµ ë³€ê²½: 'ì»¤ë²„' ë°©ì‹ìœ¼ë¡œ í•­ìƒ í™”ë©´ì„ ê°€ë“ ì±„ì›€
    scale_w = width / base_clip_original_size.w
    scale_h = height / base_clip_original_size.h
    
    # ë‘ ìŠ¤ì¼€ì¼ ì¤‘ ë” í° ê°’ì„ ì„ íƒí•˜ì—¬, ì´ë¯¸ì§€ê°€ ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ì™„ì „íˆ ë®ë„ë¡ í•¨
    scale_factor_cover = max(scale_w, scale_h)
    
    # Roundë¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œìˆ˜ì  ì²˜ë¦¬ ì˜¤ë¥˜ ë°©ì§€, ìµœì†Œ í¬ê¸° 1 ë³´ì¥
    resized_w_cover = max(1, round(base_clip_original_size.w * scale_factor_cover))
    resized_h_cover = max(1, round(base_clip_original_size.h * scale_factor_cover))

    # ìƒˆë¡œìš´ 'ì»¤ë²„' ë°©ì‹ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆëœ base_clip ìƒì„±
    base_clip = base_clip_original_size.resized((resized_w_cover, resized_h_cover)).with_duration(duration)

    clip_width = base_clip.w
    clip_height = base_clip.h

    motion_type = random.choice(["zoom_in_out", "left_to_right", "right_to_left", "static"])

    # ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ ê¸°ë³¸ ìœ„ì¹˜
    center_x = round((width - clip_width) / 2)
    center_y = round((height - clip_height) / 2)

    if motion_type == "zoom_in_out":
        start_scale = 1.0
        end_scale = 1.05
        scale_diff = end_scale - start_scale

        # í™”ë©´ì— ê½‰ ì±„ìš°ë„ë¡ ì»¤ë²„ ë¦¬ì‚¬ì´ì¦ˆ ë¨¼ì € ì§„í–‰
        scale_w = width / base_clip_original_size.w
        scale_h = height / base_clip_original_size.h
        base_scale = max(scale_w, scale_h)

        base_clip = base_clip_original_size.resized(base_scale).with_duration(duration)

        def zoom_factor(t):
            return start_scale + scale_diff * (t / duration)

        def position(t):
            scale = zoom_factor(t)
            w_scaled = base_clip.w * scale
            h_scaled = base_clip.h * scale
            x = round((width - w_scaled) / 2)
            y = round((height - h_scaled) / 2)
            # yê°€ ìŒìˆ˜ë©´ 0ìœ¼ë¡œ ë³´ì •í•´ì„œ ì•„ë˜ ê²€ì€ ì—¬ë°± ë°©ì§€
            if y < 0:
                y = 0
            return (x, y)

        zoomed_clip = base_clip.resized(zoom_factor).with_position(position)

        return zoomed_clip


    elif motion_type == "left_to_right":
        if clip_width > width:
            max_move = clip_width - width

            # ğŸ’¡ ì°¨ì´ê°€ ì•„ì£¼ ì‘ìœ¼ë©´ ê±°ì˜ ê³ ì • (ì˜ˆ: 30í”½ì…€ ì´í•˜)
            if max_move < 30:
                return base_clip.with_position((center_x, center_y))

            start_ratio = 0.3
            end_ratio = 0.6
            move_ratio = end_ratio - start_ratio

            start_offset = -max_move * start_ratio
            move_distance = max_move * move_ratio

            def ease_in_out(t):
                progress = t / duration
                return 3 * (progress ** 2) - 2 * (progress ** 3)

            def position(t):
                eased = ease_in_out(t)
                x = round(start_offset + move_distance * eased)
                y = center_y
                return (x, y)

            return base_clip.with_position(position)
        else:
            return base_clip.with_position((center_x, center_y))


    elif motion_type == "right_to_left":
        if clip_width > width:
            max_move = clip_width - width

            # ğŸ’¡ ì°¨ì´ê°€ ì•„ì£¼ ì‘ìœ¼ë©´ ê±°ì˜ ê³ ì •
            if max_move < 30:
                return base_clip.with_position((center_x, center_y))

            start_ratio = 0.3
            end_ratio = 0.6
            move_ratio = end_ratio - start_ratio

            start_offset = -max_move * end_ratio
            move_distance = max_move * move_ratio

            def ease_in_out(t):
                progress = t / duration
                return 3 * (progress ** 2) - 2 * (progress ** 3)

            def position(t):
                eased = ease_in_out(t)
                x = round(start_offset - move_distance * eased)
                y = center_y
                return (x, y)

            return base_clip.with_position(position)
        else:
            return base_clip.with_position((center_x, center_y))


    else: # "static" (ê³ ì •)
        # ì´ë¯¸ì§€ê°€ í”„ë ˆì„ ì¤‘ì•™ì— ê³ ì •ë˜ì–´ ì˜ë¦¬ì§€ ì•Šê³  ë³´ì—¬ì§‘ë‹ˆë‹¤.
        # round()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œìˆ˜ì  ì²˜ë¦¬ ì˜¤ë¥˜ ë°©ì§€
        return base_clip.with_position((center_x, center_y))
    
def auto_split_title(text: str, max_first_line_chars=18):
    words = text.split()
    total_chars = sum(len(w) for w in words)
    target = total_chars // 2

    char_count = 0
    split_idx = None
    for i, word in enumerate(words):
        char_count += len(word)
        if (char_count >= target or char_count >= max_first_line_chars) and i < len(words) - 1:
            split_idx = i + 1
            break

    if split_idx is None:
        return text, ""  # í•œ ì¤„
    return " ".join(words[:split_idx]), " ".join(words[split_idx:])

# âœ… ì˜ìƒ ìƒì„± ë©”ì¸ í•¨ìˆ˜
def create_video_with_segments(image_paths, segments, audio_path, topic_title,
                               include_topic_title=True, bgm_path="", save_path="assets/video.mp4"):
    video_width = 720
    video_height = 1080
    clips = []

    # ë¹„ë””ì˜¤ì˜ ì „ì²´ ì˜ˆìƒ ì§€ì† ì‹œê°„ ê³„ì‚°
    # segmentsê°€ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´ ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ì˜ ë ì‹œê°„ì„ ì´ ì§€ì† ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©
    if segments:
        total_video_duration = segments[-1]['end']
    else:
        # segmentsê°€ ë¹„ì–´ìˆëŠ” ê·¹ë‹¨ì ì¸ ê²½ìš°ë¥¼ ìœ„í•œ í´ë°± (ìµœì†Œ 10ì´ˆ)
        total_video_duration = 10 

    # ì˜¤ë””ì˜¤ í´ë¦½ ì´ˆê¸°í™” (audio_pathê°€ ì—†ìœ¼ë©´ ë¬´ìŒ í´ë¦½ ìƒì„±)
    if audio_path and os.path.exists(audio_path):
        audio = AudioFileClip(audio_path)
    else:
        # ë¬´ìŒ ì˜¤ë””ì˜¤ í´ë¦½ ìƒì„± (moviepyê°€ Noneì„ ì²˜ë¦¬í•˜ì§€ ëª»í•˜ë¯€ë¡œ)
        # np.array([[0.0, 0.0]])ëŠ” ë¬´ìŒ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
        audio = AudioArrayClip(np.array([[0.0, 0.0]]), fps=44100).with_duration(total_video_duration)
        print("ğŸ”Š ìŒì„± íŒŒì¼ì´ ì—†ì–´ ë¬´ìŒ ì˜¤ë””ì˜¤ íŠ¸ë™ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    # segments ê°œìˆ˜ì— ë§ì¶° ì´ë¯¸ì§€ë„ 1:1ë¡œ ë§¤ì¹­
    num_images_needed = len(segments)
    if len(image_paths) < num_images_needed:
        # ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ë°˜ë³µ ì‚¬ìš©
        image_paths += [image_paths[-1]] * (num_images_needed - len(image_paths))

    for i, seg in enumerate(segments):
        start = seg['start']
        # ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ durationì€ í•´ë‹¹ ì„¸ê·¸ë¨¼íŠ¸ì˜ ì‹œì‘ ì‹œê°„ê³¼ ë ì‹œê°„ì˜ ì°¨ì´ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
        duration = seg['end'] - start

        img_path = image_paths[i]

        # ì´ë¯¸ì§€ í•˜ë‚˜ë‹¹ motion clip ìƒì„±
        image_clip = create_motion_clip(img_path, duration, video_width, video_height)

        current_segment_clips = [image_clip]

        if include_topic_title:
            font_path = os.path.join("assets", "fonts", "Pretendard-Bold.ttf")
            line1, line2 = auto_split_title(topic_title)
            formatted_title = line1 + ("\n" + line2 if line2 else "")
            max_title_width = video_width - 40  # ì¢Œìš° ì—¬ë°±

            used_caption = False
            title_clip = None

            # 1) ê°€ëŠ¥í•˜ë©´ caption + align="center" ì‚¬ìš©
            try:
                title_clip = TextClip(
                    text=formatted_title + "\n",  # í•˜ë‹¨ ì˜ë¦¼ ë°©ì§€ìš© ê°œí–‰
                    font_size=48,
                    color="white",
                    font=font_path,
                    stroke_color="skyblue",
                    stroke_width=1,
                    method="caption",
                    size=(max_title_width, None),
                    align="center",
                ).with_duration(duration)
                used_caption = True
            except TypeError:
                title_clip = None  # í´ë°± ì§„í–‰

            # 2) í´ë°±: label í•œ ê°œë¡œ ë§Œë“¤ë˜ 'ì‹œê°ì  ê°€ìš´ë°' êµ¬í˜„
            wrapped_lines = None  # dummy ìƒì„± ì‹œ ì¬ì‚¬ìš©
            if title_clip is None:
                def line_width(s: str) -> int:
                    if not s:
                        return 0
                    c = TextClip(text=s, font=font_path, font_size=48, method="label")
                    w = c.w
                    c.close()
                    return w

                def wrap_to_width(text: str, max_w: int):
                    words = text.split()
                    lines, cur = [], ""
                    for w in words:
                        test = (cur + " " + w).strip()
                        if not cur or line_width(test) <= max_w:
                            cur = test
                        else:
                            lines.append(cur)
                            cur = w
                    if cur:
                        lines.append(cur)
                    return lines

                wrapped_lines = []
                for block in formatted_title.split("\n"):
                    if block.strip():
                        wrapped_lines += wrap_to_width(block, max_title_width)
                if not wrapped_lines:
                    wrapped_lines = [""]

                # ê° ì¤„ í­ì„ ë§ì¶° 'ê°€ìš´ë°ì²˜ëŸ¼' ë³´ì´ê²Œ NBSP íŒ¨ë”©
                maxw = max(line_width(l) for l in wrapped_lines)
                spacew = max(line_width("\u00A0"), 1)
                centered_lines = []
                for l in wrapped_lines:
                    lw = line_width(l)
                    pad = int(round((maxw - lw) / (2 * spacew))) if maxw > lw else 0
                    centered_lines.append("\u00A0" * pad + l)

                final_text = "\n".join(centered_lines) + "\n"  # í•˜ë‹¨ ì˜ë¦¼ ë°©ì§€ìš© ê°œí–‰
                title_clip = TextClip(
                    text=final_text,
                    font_size=48,
                    color="white",
                    font=font_path,
                    stroke_color="skyblue",
                    stroke_width=1,
                    method="label",
                ).with_duration(duration)
                used_caption = False

            # 3) ë™ì  íƒ€ì´í‹€ë°” ë†’ì´ ê³„ì‚° (ê·¸ëŒ€ë¡œ)
            pad_y = 16
            if used_caption:
                dummy = TextClip(
                    text=formatted_title,
                    font_size=48,
                    font=font_path,
                    method="caption",
                    size=(max_title_width, None),
                    align="center",
                )
            else:
                dummy_text = "\n".join(wrapped_lines) if wrapped_lines else formatted_title
                dummy = TextClip(
                    text=dummy_text,
                    font_size=48,
                    font=font_path,
                    method="label",
                )
            title_bar_height = dummy.h + pad_y * 2
            dummy.close()

            # ë°”ëŠ” í™”ë©´ ë§¨ ìœ„ì— ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
            black_bar = ColorClip(size=(video_width, title_bar_height), color=(0, 0, 0)).with_duration(duration)
            black_bar = black_bar.with_position(("center", "top"))

            # 4) í…ìŠ¤íŠ¸ë§Œ ì•„ë˜ë¡œ ì‚´ì§ ë‚´ë¦¬ê¸°
            x = round((video_width - title_clip.w) / 2)

            text_offset_y = 10  # â†“ ì›í•˜ëŠ” ë§Œí¼ ì¡°ì ˆ (ì–‘ìˆ˜ë©´ ì•„ë˜ë¡œ, ìŒìˆ˜ë©´ ìœ„ë¡œ)
            base_y = round((title_bar_height - title_clip.h) / 2)
            y = base_y + text_offset_y

            # ë°” ë°–ìœ¼ë¡œ ë‚˜ê°€ì§€ ì•Šë„ë¡ í´ë¨í”„
            y = max(0, min(y, title_bar_height - title_clip.h))

            title_clip = title_clip.with_position((x, y))

            current_segment_clips.append(black_bar)
            current_segment_clips.append(title_clip)

        segment_clip = CompositeVideoClip(current_segment_clips, size=(video_width, video_height)).with_duration(duration)

        clips.append(segment_clip)

    final_audio = audio

    if bgm_path and os.path.exists(bgm_path):
        bgm_raw = AudioFileClip(bgm_path)
        bgm_array = bgm_raw.to_soundarray(fps=44100) * 0.2
        repeat_count = int(np.ceil(audio.duration / bgm_raw.duration))
        bgm_array = np.tile(bgm_array, (repeat_count, 1))
        bgm_array = bgm_array[:int(audio.duration * 44100)]

        bgm = AudioArrayClip(bgm_array, fps=44100).with_duration(audio.duration)
        final_audio = CompositeAudioClip([audio, bgm])

    final = concatenate_videoclips(clips, method="chain")\
        .with_audio(final_audio)\
        .with_fps(24)
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    final.write_videofile(save_path, codec="libx264", audio_codec="aac")
    print(f"âœ… íƒ€ì´ë° ë™ê¸°í™” ì˜ìƒ ì €ì¥ ì™„ë£Œ: {save_path}")
    return save_path

ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()

# âœ… ìë§‰ ì¶”ê°€ í•¨ìˆ˜
def add_subtitles_to_video(input_video_path, ass_path, output_path="assets/video_with_subs.mp4"):
    fonts_dir = os.path.abspath(os.path.join("assets", "fonts"))

    command = [
        ffmpeg_path , "-y", "-i", input_video_path,
        "-vf", f"ass={ass_path}:fontsdir={fonts_dir}",
        "-c:a", "copy", output_path
    ]
    try:
        subprocess.run(command, check=True)
        print(f"âœ… ìë§‰ í¬í•¨ ì˜ìƒ ì €ì¥ ì™„ë£Œ: {output_path}")
    except subprocess.CalledProcessError as e:
        print("âŒ FFmpeg ì‹¤í–‰ ì‹¤íŒ¨:", e)
    return output_path

def create_dark_text_video(script_text, title_text, audio_path=None, bgm_path="", save_path="assets/dark_text_video.mp4"):
    video_width, video_height = 720, 1080
    font_path = os.path.abspath(os.path.join("assets", "fonts", "Pretendard-Bold.ttf"))
    if not os.path.exists(font_path):
        raise FileNotFoundError(f"í°íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤: {font_path}")

    # ê¸¸ì´: ì˜¤ë””ì˜¤ ì—†ìœ¼ë©´ 2ì´ˆ
    if audio_path and os.path.exists(audio_path):
        audio = AudioFileClip(audio_path); duration = audio.duration
    else:
        duration = 2
        audio = AudioArrayClip(np.array([[0.0, 0.0]]), fps=44100).with_duration(duration)

    bg_clip = ColorClip(size=(video_width, video_height), color=(0, 0, 0)).with_duration(duration)

    # ===== ë ˆì´ì•„ì›ƒ ìƒìˆ˜ =====
    TOP_MARGIN = 150
    BOTTOM_MARGIN = 80
    SAFE_BOTTOM_PAD = 24
    SAFE_SIDE_PAD = 24
    LEFT_BLEED_PAD = 12
    CONTENT_WIDTH = video_width - SAFE_SIDE_PAD * 2

    # ===== ì œëª© 2ì¤„ + ë§ì¤„ì„ =====
    def ellipsize_two_lines(text, max_chars_per_line=20):
        if not text:
            return ""
        import textwrap
        wrapped = textwrap.wrap(text.strip(), width=max_chars_per_line, break_long_words=True, break_on_hyphens=False)
        if len(wrapped) <= 2:
            return "\n".join(wrapped)
        out = wrapped[:2]
        out[1] = (out[1].rstrip()[:-1] + "â€¦") if len(out[1].rstrip()) > 0 else "â€¦"
        return "\n".join(out)

    title_text = ellipsize_two_lines(title_text or "", max_chars_per_line=18)

    # ===== í­ ì¸¡ì • ìœ í‹¸(ë˜í•‘ì—ë§Œ ì‚¬ìš©) =====
    def line_width(s: str, fs: int) -> int:
        if not s:
            return 0
        c = TextClip(text=s, font=font_path, font_size=fs, method="label")
        w = c.w
        c.close()
        return w

    # ë‹¨ì–´ ë‹¨ìœ„ ë˜í•‘
    def wrap_to_width(text: str, max_w: int, fs: int):
        words = text.split()
        lines, cur = [], ""
        for w in words:
            test = (cur + " " + w).strip()
            if not cur or line_width(test, fs) <= max_w:
                cur = test
            else:
                lines.append(cur); cur = w
        if cur: lines.append(cur)
        return lines if lines else [""]

    # ì…ë ¥ ì¤„ë°”ê¿ˆ ë³´ì¡´ + ë¸”ë¡ë³„ ë˜í•‘
    def wrap_preserving_newlines(text: str, max_w: int, fs: int):
        out = []
        for block in (text or "").splitlines():
            if block.strip() == "":
                out.append("")              # ë¹ˆ ì¤„ ìœ ì§€
            else:
                out.extend(wrap_to_width(block, max_w, fs))
        return out

    # ì œëª© ê°€ìš´ë° ë§ì¶¤(ì‹œê°ì )
    def center_label_multiline(raw_text: str, max_w: int, fs: int, pad_char="\u00A0"):
        blocks = raw_text.split("\n")
        lines = [b if b.strip() else "" for b in blocks]

        def _w(s):
            if not s: return 0
            c = TextClip(text=s, font=font_path, font_size=fs, method="label")
            w = c.w; c.close(); return w

        maxw = max((_w(l) for l in lines), default=0)
        spacew = max(_w(pad_char), 1)
        centered = []
        for l in lines:
            lw = _w(l)
            pad = int(round((maxw - lw) / (2 * spacew))) if maxw > lw else 0
            centered.append(pad_char * pad + l)
        return "\n".join(centered) + "\n"

    # ===== ì œëª© =====
    title_fontsize = 38
    max_title_width = CONTENT_WIDTH - 2 * LEFT_BLEED_PAD
    centered_title_text = center_label_multiline(title_text, max_title_width, title_fontsize)

    title_clip_tmp = TextClip(text=centered_title_text, font=font_path, font_size=title_fontsize,
                              color="white", method="label")
    title_h = title_clip_tmp.h
    title_y = TOP_MARGIN
    title_x = int(SAFE_SIDE_PAD + LEFT_BLEED_PAD + ((CONTENT_WIDTH - 2 * LEFT_BLEED_PAD) - title_clip_tmp.w) / 2)
    title_clip = title_clip_tmp.with_position((title_x, int(title_y))).with_duration(duration)

    # ===== ë³¸ë¬¸(ì¤„ê°„ê²©/ì˜ë¦¼ ë°©ì§€) =====
    GAP_TITLE_BODY = 32
    allowed_body_height = video_height - BOTTOM_MARGIN - (title_y + title_h + GAP_TITLE_BODY) - SAFE_BOTTOM_PAD

    if allowed_body_height <= 0:
        video = CompositeVideoClip([bg_clip, title_clip], size=(video_width, video_height)).with_duration(duration)
    else:
        body_fontsize  = 26               # í•„ìš”ì‹œ ì¡°ì •
        body_width_px  = CONTENT_WIDTH

        # ì¤„ ê°„ê²©/ì—¬ë°±(ë„ˆë¬´ í¬ì§€ ì•Šê²Œ ì•ˆì •ê°’)
        LINE_GAP       = int(round(body_fontsize * 0.45))  # ì¤„ ì‚¬ì´ ì¶”ê°€ ê°„ê²©
        TOP_PAD_PX     = int(round(body_fontsize * 0.20))  # ì²« ì¤„ ìœ„ ì—¬ìœ 
        BOTTOM_PAD_PX  = int(round(body_fontsize * 0.40))  # ë§ˆì§€ë§‰ ì¤„ ì•„ë˜ ì—¬ìœ 
        DESCENDER_PAD  = int(round(body_fontsize * 0.30))  # ê° ì¤„ í•˜ë‹¨ ë³´ê°•(ì˜ë¦¼ ë°©ì§€ í¬ì¸íŠ¸)

        MIN_FONT_SIZE   = 14
        MIN_WIDTH_RATIO = 0.60
        min_width_px    = int(CONTENT_WIDTH * MIN_WIDTH_RATIO)

        # ì¢Œìš° 1.5 ê¸€ì ë‚´ë¶€ íŒ¨ë”©(í•œê¸€/ë¼í‹´ í˜¼ìš©)
        base_char_w = max(8, line_width("ê°€", body_fontsize), line_width("M", body_fontsize))
        INNER_PAD = int(round(base_char_w * 1.5))

        NBSP, HAIR = "\u00A0", "\u200A"

        def spacer(h):
            return ColorClip(size=(1, max(1, int(h))), color=(0, 0, 0)).with_opacity(0)

        def build_body(fs: int, width_px: int):
            eff_wrap_w = max(20, width_px - 2 * INNER_PAD - 2 * LEFT_BLEED_PAD)
            lines = wrap_preserving_newlines((script_text or "").rstrip(), eff_wrap_w, fs)

            clips = []
            y = TOP_PAD_PX
            maxw = 1

            for i, line in enumerate(lines):
                if line.strip() == "":
                    # ë¹ˆ ì¤„ì€ í•œ ì¤„ ë†’ì´+ê°„ê²© ë§Œí¼ ë„ì›€(ë¬¸ë‹¨ ê°„ê²© ìœ ì§€)
                    sg = spacer(fs + LINE_GAP)
                    clips.append(sg.with_position((0, y))); y += sg.h
                    continue

                # (ì¤‘ìš”) ê° ì¤„ì„ caption ëª¨ë“œë¡œ ê°œë³„ ë Œë” â†’ í°íŠ¸ ë©”íŠ¸ë¦­ ë³´ì¡´ & í•˜ë‹¨ ì˜ë¦¼ ë°©ì§€
                # ì¢Œìš° ë² ì–´ë§ ë³´í˜¸ë¥¼ ìœ„í•´ NBSP/HAIR ì¶”ê°€
                safe_line = NBSP + line + HAIR
                c = TextClip(
                    text=safe_line,
                    font=font_path,
                    font_size=fs,
                    color="white",
                    method="caption",
                    size=(eff_wrap_w, None),   # í•œ ì¤„ ìº¡ì…˜ í­ ì œí•œ
                    interline=0                # ë‹¨ì¼ ì¤„ì´ë¼ ì˜ë¯¸ ì—†ìŒ
                )
                clips.append(c.with_position((0, y)))
                y += c.h

                # ê° ì¤„ í•˜ë‹¨ì— descender íŒ¨ë“œ ì¶”ê°€(ì•„ë«ë¶€ë¶„ ì˜ë¦¼ ë°©ì§€ì˜ í•µì‹¬)
                if DESCENDER_PAD:
                    pd = spacer(DESCENDER_PAD)
                    clips.append(pd.with_position((0, y)))
                    y += pd.h

                # ë‹¤ìŒ ì¤„ê³¼ì˜ ê°„ê²©
                if i < len(lines) - 1:
                    gap = spacer(LINE_GAP)
                    clips.append(gap.with_position((0, y))); y += gap.h

                maxw = max(maxw, c.w)

            total_h = y + BOTTOM_PAD_PX
            if not clips:
                return CompositeVideoClip([spacer(int(fs * 1.2)).with_position((0, 0))],
                                          size=(1, int(fs * 1.2))).with_duration(duration)

            return CompositeVideoClip(clips, size=(maxw, total_h)).with_duration(duration)

        # allowed_body_heightì— ë§ì¶° ì¡°ì •
        fit_clip = None
        for _ in range(80):
            body_label = build_body(body_fontsize, body_width_px)
            if body_label.h <= allowed_body_height:
                fit_clip = body_label
                break
            if body_fontsize > MIN_FONT_SIZE:
                body_fontsize = max(MIN_FONT_SIZE, body_fontsize - 2)
                base_char_w = max(8, line_width("ê°€", body_fontsize), line_width("M", body_fontsize))
                INNER_PAD = int(round(base_char_w * 1.5))
                continue
            if body_width_px > min_width_px:
                body_width_px = max(min_width_px, body_width_px - 10)
                continue
            # ìµœí›„: ë¹„ìœ¨ ì¶•ì†Œ
            scale = allowed_body_height / float(body_label.h)
            fit_clip = body_label.resized(scale)
            break

        if fit_clip is None:
            fit_clip = build_body(body_fontsize, body_width_px)

        # ì¢Œìš° 1.5ì íŒ¨ë”© ë˜í¼
        body_wrapper_w = fit_clip.w + 2 * INNER_PAD
        body_wrapper_h = fit_clip.h
        body_wrapper = CompositeVideoClip(
            [fit_clip.with_position((INNER_PAD, 0))],
            size=(body_wrapper_w, body_wrapper_h)
        ).with_duration(duration)

        # ì¤‘ì•™ ì •ë ¬(ë˜í¼ ê¸°ì¤€)
        body_x = int(SAFE_SIDE_PAD + ((CONTENT_WIDTH - body_wrapper.w) / 2))
        body_y = int(title_y + title_h + GAP_TITLE_BODY)
        body_clip = body_wrapper.with_position((body_x, body_y)).with_duration(duration)

        # í•˜ë‹¨ íˆ¬ëª… íŒ¨ë“œ
        pad_clip = ColorClip(size=(video_width, SAFE_BOTTOM_PAD), color=(0, 0, 0)).with_opacity(0) \
                    .with_duration(duration).with_position(("center", video_height - SAFE_BOTTOM_PAD))

        video = CompositeVideoClip([bg_clip, title_clip, body_clip, pad_clip],
                                   size=(video_width, video_height)).with_duration(duration)

    # ===== ì˜¤ë””ì˜¤ & ì €ì¥ =====
    final_audio = audio
    if bgm_path and os.path.exists(bgm_path):
        bgm = AudioFileClip(bgm_path).volumex(0.2).with_duration(duration)
        final_audio = CompositeAudioClip([audio, bgm])

    final_video = video.with_audio(final_audio).with_fps(24)
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    final_video.write_videofile(save_path, codec="libx264", audio_codec="aac")
    return save_path
